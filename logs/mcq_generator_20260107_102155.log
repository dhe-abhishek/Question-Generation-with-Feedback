2026-01-07 10:21:56,353 - matplotlib - DEBUG - matplotlib data path: D:\Learning Analytics\Learning-AI\Learning_Analytics-API\venv\Lib\site-packages\matplotlib\mpl-data
2026-01-07 10:21:56,358 - matplotlib - DEBUG - CONFIGDIR=C:\Users\Administrator\.matplotlib
2026-01-07 10:21:56,359 - matplotlib - DEBUG - interactive is False
2026-01-07 10:21:56,359 - matplotlib - DEBUG - platform is win32
2026-01-07 10:21:56,385 - matplotlib - DEBUG - CACHEDIR=C:\Users\Administrator\.matplotlib
2026-01-07 10:21:56,387 - matplotlib.font_manager - DEBUG - Using fontManager instance from C:\Users\Administrator\.matplotlib\fontlist-v390.json
2026-01-07 10:21:57,729 - datasets - DEBUG - PyTorch version 2.9.0 available.
2026-01-07 10:21:59,297 - ragas._analytics - DEBUG - Starting AnalyticsBatcher thread with interval 10 seconds
2026-01-07 10:21:59,786 - relevancy_utils - INFO - Starting Ragas scorer initialization...
2026-01-07 10:22:00,123 - relevancy_utils - DEBUG - ChatGroq LLM initialized.
2026-01-07 10:22:00,854 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cpu
2026-01-07 10:22:00,854 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2026-01-07 10:22:00,855 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): huggingface.co:443
2026-01-07 10:22:01,250 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/modules.json HTTP/1.1" 307 0
2026-01-07 10:22:01,269 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/modules.json HTTP/1.1" 200 0
2026-01-07 10:22:01,487 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/config_sentence_transformers.json HTTP/1.1" 307 0
2026-01-07 10:22:01,507 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config_sentence_transformers.json HTTP/1.1" 200 0
2026-01-07 10:22:01,725 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/config_sentence_transformers.json HTTP/1.1" 307 0
2026-01-07 10:22:01,744 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config_sentence_transformers.json HTTP/1.1" 200 0
2026-01-07 10:22:01,963 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/README.md HTTP/1.1" 307 0
2026-01-07 10:22:01,982 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/README.md HTTP/1.1" 200 0
2026-01-07 10:22:02,208 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/modules.json HTTP/1.1" 307 0
2026-01-07 10:22:02,227 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/modules.json HTTP/1.1" 200 0
2026-01-07 10:22:02,629 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/sentence_bert_config.json HTTP/1.1" 307 0
2026-01-07 10:22:02,648 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/sentence_bert_config.json HTTP/1.1" 200 0
2026-01-07 10:22:02,870 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/adapter_config.json HTTP/1.1" 404 0
2026-01-07 10:22:03,094 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 307 0
2026-01-07 10:22:03,120 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config.json HTTP/1.1" 200 0
2026-01-07 10:22:03,396 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2026-01-07 10:22:03,416 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/tokenizer_config.json HTTP/1.1" 200 0
2026-01-07 10:22:03,659 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "GET /api/models/sentence-transformers/all-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2026-01-07 10:22:03,901 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/1_Pooling/config.json HTTP/1.1" 307 0
2026-01-07 10:22:03,925 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/1_Pooling%2Fconfig.json HTTP/1.1" 200 0
2026-01-07 10:22:04,162 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "GET /api/models/sentence-transformers/all-MiniLM-L6-v2 HTTP/1.1" 200 6861
2026-01-07 10:22:04,167 - relevancy_utils - DEBUG - HuggingFace Embeddings initialized.
2026-01-07 10:22:04,168 - relevancy_utils - INFO - Ragas ResponseRelevancy scorer initialized successfully.
2026-01-07 10:22:04,168 - faithfulness_utils - INFO - Initializing Faithfulness scorer...
2026-01-07 10:22:04,479 - faithfulness_utils - INFO - Faithfulness scorer initialized successfully.
2026-01-07 10:22:04,486 - werkzeug - WARNING -  * Debugger is active!
2026-01-07 10:22:04,487 - werkzeug - INFO -  * Debugger PIN: 103-783-783
2026-01-07 10:25:51,064 - routes - INFO - Rendering home page
2026-01-07 10:25:51,077 - werkzeug - INFO - 127.0.0.1 - - [07/Jan/2026 10:25:51] "GET / HTTP/1.1" 200 -
2026-01-07 10:25:56,465 - routes - INFO - Rendering Question generator page
2026-01-07 10:25:56,470 - werkzeug - INFO - 127.0.0.1 - - [07/Jan/2026 10:25:56] "GET /mcq-generator HTTP/1.1" 200 -
2026-01-07 10:26:24,185 - routes - INFO - Received Question generation request
2026-01-07 10:26:24,200 - validation - INFO - File and parameters validated successfully.
2026-01-07 10:26:24,200 - file_utils - DEBUG - File 13-queryexecution.pdf allowed: True
2026-01-07 10:26:24,209 - file_utils - INFO - File saved to: D:\Learning Analytics\Learning-AI\Question_and_Answer_Generation\uploads\13-queryexecution.pdf
2026-01-07 10:26:24,339 - pdf_extraction_util - INFO - Successfully extracted 38407 characters from 13-queryexecution.pdf
2026-01-07 10:26:25,192 - question_generation - INFO - QuestionGenerator initialized with model: gemini-2.5-flash
2026-01-07 10:26:25,196 - question_generation - INFO - Generating structured content using model gemini-2.5-flash...
2026-01-07 10:26:25,197 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2026-01-07 10:26:25,202 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2026-01-07 10:26:25,232 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000160708CD010>
2026-01-07 10:26:25,232 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x00000160708D45F0> server_hostname='generativelanguage.googleapis.com' timeout=None
2026-01-07 10:26:25,253 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000016070969E50>
2026-01-07 10:26:25,254 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2026-01-07 10:26:25,254 - httpcore.http11 - DEBUG - send_request_headers.complete
2026-01-07 10:26:25,254 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2026-01-07 10:26:25,255 - httpcore.http11 - DEBUG - send_request_body.complete
2026-01-07 10:26:25,255 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2026-01-07 10:26:55,808 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Wed, 07 Jan 2026 04:56:55 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=30540'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2026-01-07 10:26:55,809 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
2026-01-07 10:26:55,809 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2026-01-07 10:26:55,810 - httpcore.http11 - DEBUG - receive_response_body.complete
2026-01-07 10:26:55,810 - httpcore.http11 - DEBUG - response_closed.started
2026-01-07 10:26:55,810 - httpcore.http11 - DEBUG - response_closed.complete
2026-01-07 10:26:55,835 - question_generation - INFO - Successfully separated 10 questions and 10 answer key items.
2026-01-07 10:26:55,837 - file_utils - INFO - Cleaned up file: D:\Learning Analytics\Learning-AI\Question_and_Answer_Generation\uploads\13-queryexecution.pdf
2026-01-07 10:26:55,837 - pdf_generation - INFO - Creating PDF file: D:\Learning Analytics\Learning-AI\Question_and_Answer_Generation\results\generated_mcqs_13-queryexecution_questions.pdf
2026-01-07 10:26:55,854 - fpdf.fpdf - DEBUG - Page break on page 1 at y=277 for element of height 6 > 277
2026-01-07 10:26:55,862 - fpdf.fpdf - DEBUG - Page break on page 2 at y=273 for element of height 6 > 277
2026-01-07 10:26:55,874 - fpdf.fpdf - DEBUG - Page break on page 3 at y=277 for element of height 6 > 277
2026-01-07 10:26:55,879 - fpdf.output - DEBUG - Final size summary of the biggest document sections:
2026-01-07 10:26:55,879 - fpdf.output - DEBUG - - pages: 5.9KiB
2026-01-07 10:26:55,879 - fpdf.output - DEBUG - - fonts: 307.0B
2026-01-07 10:26:55,880 - pdf_generation - INFO - PDF successfully generated at D:\Learning Analytics\Learning-AI\Question_and_Answer_Generation\results\generated_mcqs_13-queryexecution_questions.pdf
2026-01-07 10:26:55,880 - file_utils - INFO - Saving TXT results for: 13-queryexecution.pdf
2026-01-07 10:26:55,880 - pdf_generation - INFO - Saving merged questions to text file: generated_mcqs_13-queryexecution_key.txt
2026-01-07 10:26:55,882 - pdf_generation - INFO - Successfully saved 10 questions to text file.
2026-01-07 10:26:55,882 - file_utils - INFO - TXT file saved: generated_mcqs_13-queryexecution_key.txt
2026-01-07 10:26:55,883 - routes - INFO - Successfully generated 10 questions.
2026-01-07 10:26:55,890 - routes - ERROR - Error during question generation process: 'score' is undefined
Traceback (most recent call last):
  File "D:\Learning Analytics\Learning-AI\Question_and_Answer_Generation\app\routes.py", line 122, in generate_questions
    return render_template(
        'results.html',
    ...<2 lines>...
        txt_filename=txt_filename # Use txt_filename
    )
  File "D:\Learning Analytics\Learning-AI\Learning_Analytics-API\venv\Lib\site-packages\flask\templating.py", line 150, in render_template
    return _render(app, template, context)
  File "D:\Learning Analytics\Learning-AI\Learning_Analytics-API\venv\Lib\site-packages\flask\templating.py", line 131, in _render
    rv = template.render(context)
  File "D:\Learning Analytics\Learning-AI\Learning_Analytics-API\venv\Lib\site-packages\jinja2\environment.py", line 1295, in render
    self.environment.handle_exception()
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "D:\Learning Analytics\Learning-AI\Learning_Analytics-API\venv\Lib\site-packages\jinja2\environment.py", line 942, in handle_exception
    raise rewrite_traceback_stack(source=source)
  File "D:\Learning Analytics\Learning-AI\Question_and_Answer_Generation\app\templates\results.html", line 154, in top-level template code
    {% set percentage = (score / total * 100) | round %}
    ^^^^^^^^^^^^^
jinja2.exceptions.UndefinedError: 'score' is undefined
2026-01-07 10:26:55,893 - werkzeug - INFO - 127.0.0.1 - - [07/Jan/2026 10:26:55] "[32mPOST /generate HTTP/1.1[0m" 302 -
2026-01-07 10:26:55,898 - routes - INFO - Rendering Question generator page
2026-01-07 10:26:55,898 - werkzeug - INFO - 127.0.0.1 - - [07/Jan/2026 10:26:55] "GET /mcq-generator HTTP/1.1" 200 -
2026-01-07 10:30:50,953 - routes - INFO - Rendering Question generator page
2026-01-07 10:30:50,954 - werkzeug - INFO - 127.0.0.1 - - [07/Jan/2026 10:30:50] "GET /mcq-generator HTTP/1.1" 200 -
2026-01-07 10:30:58,897 - routes - INFO - Received Question generation request
2026-01-07 10:30:58,938 - validation - INFO - File and parameters validated successfully.
2026-01-07 10:30:58,939 - file_utils - DEBUG - File 03-storage1.pdf allowed: True
2026-01-07 10:30:58,944 - file_utils - INFO - File saved to: D:\Learning Analytics\Learning-AI\Question_and_Answer_Generation\uploads\03-storage1.pdf
2026-01-07 10:30:59,036 - pdf_extraction_util - INFO - Successfully extracted 26430 characters from 03-storage1.pdf
2026-01-07 10:30:59,799 - question_generation - INFO - QuestionGenerator initialized with model: gemini-2.5-flash
2026-01-07 10:30:59,800 - question_generation - INFO - Generating structured content using model gemini-2.5-flash...
2026-01-07 10:30:59,801 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2026-01-07 10:30:59,803 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2026-01-07 10:30:59,816 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000016071A82850>
2026-01-07 10:30:59,816 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x0000016071A84690> server_hostname='generativelanguage.googleapis.com' timeout=None
2026-01-07 10:30:59,836 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000016070947CE0>
2026-01-07 10:30:59,836 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2026-01-07 10:30:59,837 - httpcore.http11 - DEBUG - send_request_headers.complete
2026-01-07 10:30:59,837 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2026-01-07 10:30:59,838 - httpcore.http11 - DEBUG - send_request_body.complete
2026-01-07 10:30:59,838 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2026-01-07 10:31:14,482 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Wed, 07 Jan 2026 05:01:13 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=14631'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2026-01-07 10:31:14,482 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
2026-01-07 10:31:14,483 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2026-01-07 10:31:14,483 - httpcore.http11 - DEBUG - receive_response_body.complete
2026-01-07 10:31:14,483 - httpcore.http11 - DEBUG - response_closed.started
2026-01-07 10:31:14,483 - httpcore.http11 - DEBUG - response_closed.complete
2026-01-07 10:31:14,484 - question_generation - INFO - Successfully separated 5 questions and 5 answer key items.
2026-01-07 10:31:14,485 - file_utils - INFO - Cleaned up file: D:\Learning Analytics\Learning-AI\Question_and_Answer_Generation\uploads\03-storage1.pdf
2026-01-07 10:31:14,485 - pdf_generation - INFO - Creating PDF file: D:\Learning Analytics\Learning-AI\Question_and_Answer_Generation\results\generated_mcqs_03-storage1_questions.pdf
2026-01-07 10:31:14,490 - fpdf.fpdf - DEBUG - Page break on page 1 at y=277 for element of height 6 > 277
2026-01-07 10:31:14,492 - fpdf.output - DEBUG - Final size summary of the biggest document sections:
2026-01-07 10:31:14,492 - fpdf.output - DEBUG - - pages: 2.2KiB
2026-01-07 10:31:14,492 - fpdf.output - DEBUG - - fonts: 304.0B
2026-01-07 10:31:14,493 - pdf_generation - INFO - PDF successfully generated at D:\Learning Analytics\Learning-AI\Question_and_Answer_Generation\results\generated_mcqs_03-storage1_questions.pdf
2026-01-07 10:31:14,493 - file_utils - INFO - Saving TXT results for: 03-storage1.pdf
2026-01-07 10:31:14,493 - pdf_generation - INFO - Saving merged questions to text file: generated_mcqs_03-storage1_key.txt
2026-01-07 10:31:14,493 - pdf_generation - INFO - Successfully saved 5 questions to text file.
2026-01-07 10:31:14,493 - file_utils - INFO - TXT file saved: generated_mcqs_03-storage1_key.txt
2026-01-07 10:31:14,493 - routes - INFO - Successfully generated 5 questions.
2026-01-07 10:31:14,494 - routes - ERROR - Error during question generation process: 'score' is undefined
Traceback (most recent call last):
  File "D:\Learning Analytics\Learning-AI\Question_and_Answer_Generation\app\routes.py", line 122, in generate_questions
    return render_template(
        'results.html',
    ...<2 lines>...
        txt_filename=txt_filename # Use txt_filename
    )
  File "D:\Learning Analytics\Learning-AI\Learning_Analytics-API\venv\Lib\site-packages\flask\templating.py", line 150, in render_template
    return _render(app, template, context)
  File "D:\Learning Analytics\Learning-AI\Learning_Analytics-API\venv\Lib\site-packages\flask\templating.py", line 131, in _render
    rv = template.render(context)
  File "D:\Learning Analytics\Learning-AI\Learning_Analytics-API\venv\Lib\site-packages\jinja2\environment.py", line 1295, in render
    self.environment.handle_exception()
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "D:\Learning Analytics\Learning-AI\Learning_Analytics-API\venv\Lib\site-packages\jinja2\environment.py", line 942, in handle_exception
    raise rewrite_traceback_stack(source=source)
  File "D:\Learning Analytics\Learning-AI\Question_and_Answer_Generation\app\templates\results.html", line 154, in top-level template code
    {% set percentage = (score / total * 100) | round %}
    ^^^^^^^^^^^^^
jinja2.exceptions.UndefinedError: 'score' is undefined
2026-01-07 10:31:14,495 - werkzeug - INFO - 127.0.0.1 - - [07/Jan/2026 10:31:14] "[32mPOST /generate HTTP/1.1[0m" 302 -
2026-01-07 10:31:14,498 - routes - INFO - Rendering Question generator page
2026-01-07 10:31:14,498 - werkzeug - INFO - 127.0.0.1 - - [07/Jan/2026 10:31:14] "GET /mcq-generator HTTP/1.1" 200 -
2026-01-07 10:32:06,999 - routes - INFO - Rendering home page
2026-01-07 10:32:07,001 - werkzeug - INFO - 127.0.0.1 - - [07/Jan/2026 10:32:07] "GET / HTTP/1.1" 200 -
2026-01-07 10:32:09,782 - routes - INFO - Rendering Question generator page
2026-01-07 10:32:09,784 - werkzeug - INFO - 127.0.0.1 - - [07/Jan/2026 10:32:09] "GET /mcq-generator HTTP/1.1" 200 -
2026-01-07 10:32:18,640 - routes - INFO - Received Question generation request
2026-01-07 10:32:18,651 - validation - INFO - File and parameters validated successfully.
2026-01-07 10:32:18,652 - file_utils - DEBUG - File 03-storage1.pdf allowed: True
2026-01-07 10:32:18,659 - file_utils - INFO - File saved to: D:\Learning Analytics\Learning-AI\Question_and_Answer_Generation\uploads\03-storage1.pdf
2026-01-07 10:32:18,777 - pdf_extraction_util - INFO - Successfully extracted 26430 characters from 03-storage1.pdf
2026-01-07 10:32:19,563 - question_generation - INFO - QuestionGenerator initialized with model: gemini-2.5-flash
2026-01-07 10:32:19,564 - question_generation - INFO - Generating structured content using model gemini-2.5-flash...
2026-01-07 10:32:19,564 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2026-01-07 10:32:19,565 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2026-01-07 10:32:19,597 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000016071A75480>
2026-01-07 10:32:19,597 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x0000016071A85A90> server_hostname='generativelanguage.googleapis.com' timeout=None
2026-01-07 10:32:19,616 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000016071A6CDD0>
2026-01-07 10:32:19,616 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2026-01-07 10:32:19,617 - httpcore.http11 - DEBUG - send_request_headers.complete
2026-01-07 10:32:19,617 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2026-01-07 10:32:19,618 - httpcore.http11 - DEBUG - send_request_body.complete
2026-01-07 10:32:19,618 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2026-01-07 10:32:37,026 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Wed, 07 Jan 2026 05:02:36 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=17396'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2026-01-07 10:32:37,027 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
2026-01-07 10:32:37,028 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2026-01-07 10:32:37,028 - httpcore.http11 - DEBUG - receive_response_body.complete
2026-01-07 10:32:37,028 - httpcore.http11 - DEBUG - response_closed.started
2026-01-07 10:32:37,028 - httpcore.http11 - DEBUG - response_closed.complete
2026-01-07 10:32:37,030 - question_generation - INFO - Successfully separated 5 questions and 5 answer key items.
2026-01-07 10:32:37,031 - file_utils - INFO - Cleaned up file: D:\Learning Analytics\Learning-AI\Question_and_Answer_Generation\uploads\03-storage1.pdf
2026-01-07 10:32:37,032 - pdf_generation - INFO - Creating PDF file: D:\Learning Analytics\Learning-AI\Question_and_Answer_Generation\results\generated_mcqs_03-storage1_questions.pdf
2026-01-07 10:32:37,042 - fpdf.fpdf - DEBUG - Page break on page 1 at y=277 for element of height 6 > 277
2026-01-07 10:32:37,046 - fpdf.output - DEBUG - Final size summary of the biggest document sections:
2026-01-07 10:32:37,046 - fpdf.output - DEBUG - - pages: 2.3KiB
2026-01-07 10:32:37,046 - fpdf.output - DEBUG - - fonts: 304.0B
2026-01-07 10:32:37,047 - pdf_generation - INFO - PDF successfully generated at D:\Learning Analytics\Learning-AI\Question_and_Answer_Generation\results\generated_mcqs_03-storage1_questions.pdf
2026-01-07 10:32:37,047 - file_utils - INFO - Saving TXT results for: 03-storage1.pdf
2026-01-07 10:32:37,047 - pdf_generation - INFO - Saving merged questions to text file: generated_mcqs_03-storage1_key.txt
2026-01-07 10:32:37,048 - pdf_generation - INFO - Successfully saved 5 questions to text file.
2026-01-07 10:32:37,048 - file_utils - INFO - TXT file saved: generated_mcqs_03-storage1_key.txt
2026-01-07 10:32:37,048 - routes - INFO - Successfully generated 5 questions.
2026-01-07 10:32:37,049 - routes - ERROR - Error during question generation process: 'score' is undefined
Traceback (most recent call last):
  File "D:\Learning Analytics\Learning-AI\Question_and_Answer_Generation\app\routes.py", line 122, in generate_questions
    return render_template(
        'results.html',
    ...<2 lines>...
        txt_filename=txt_filename # Use txt_filename
    )
  File "D:\Learning Analytics\Learning-AI\Learning_Analytics-API\venv\Lib\site-packages\flask\templating.py", line 150, in render_template
    return _render(app, template, context)
  File "D:\Learning Analytics\Learning-AI\Learning_Analytics-API\venv\Lib\site-packages\flask\templating.py", line 131, in _render
    rv = template.render(context)
  File "D:\Learning Analytics\Learning-AI\Learning_Analytics-API\venv\Lib\site-packages\jinja2\environment.py", line 1295, in render
    self.environment.handle_exception()
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "D:\Learning Analytics\Learning-AI\Learning_Analytics-API\venv\Lib\site-packages\jinja2\environment.py", line 942, in handle_exception
    raise rewrite_traceback_stack(source=source)
  File "D:\Learning Analytics\Learning-AI\Question_and_Answer_Generation\app\templates\results.html", line 154, in top-level template code
    {% set percentage = (score / total * 100) | round %}
    ^^^^^^^^^^^^^
jinja2.exceptions.UndefinedError: 'score' is undefined
2026-01-07 10:32:37,052 - werkzeug - INFO - 127.0.0.1 - - [07/Jan/2026 10:32:37] "[32mPOST /generate HTTP/1.1[0m" 302 -
2026-01-07 10:32:37,058 - routes - INFO - Rendering Question generator page
2026-01-07 10:32:37,059 - werkzeug - INFO - 127.0.0.1 - - [07/Jan/2026 10:32:37] "GET /mcq-generator HTTP/1.1" 200 -
2026-01-07 10:32:53,568 - routes - INFO - Received Question generation request
2026-01-07 10:32:53,579 - validation - INFO - File and parameters validated successfully.
2026-01-07 10:32:53,579 - file_utils - DEBUG - File 04-bufferpool.pdf allowed: True
2026-01-07 10:32:53,588 - file_utils - INFO - File saved to: D:\Learning Analytics\Learning-AI\Question_and_Answer_Generation\uploads\04-bufferpool.pdf
2026-01-07 10:32:53,727 - pdf_extraction_util - INFO - Successfully extracted 42260 characters from 04-bufferpool.pdf
2026-01-07 10:32:54,535 - question_generation - INFO - QuestionGenerator initialized with model: gemini-2.5-flash
2026-01-07 10:32:54,536 - question_generation - INFO - Generating structured content using model gemini-2.5-flash...
2026-01-07 10:32:54,536 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2026-01-07 10:32:54,539 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2026-01-07 10:32:54,560 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000016071A7D040>
2026-01-07 10:32:54,561 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x0000016071A86D50> server_hostname='generativelanguage.googleapis.com' timeout=None
2026-01-07 10:32:54,578 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000016071A7D370>
2026-01-07 10:32:54,578 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2026-01-07 10:32:54,579 - httpcore.http11 - DEBUG - send_request_headers.complete
2026-01-07 10:32:54,579 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2026-01-07 10:32:54,579 - httpcore.http11 - DEBUG - send_request_body.complete
2026-01-07 10:32:54,580 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2026-01-07 10:33:09,225 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Wed, 07 Jan 2026 05:03:08 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=14634'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2026-01-07 10:33:09,225 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
2026-01-07 10:33:09,226 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2026-01-07 10:33:09,226 - httpcore.http11 - DEBUG - receive_response_body.complete
2026-01-07 10:33:09,227 - httpcore.http11 - DEBUG - response_closed.started
2026-01-07 10:33:09,227 - httpcore.http11 - DEBUG - response_closed.complete
2026-01-07 10:33:09,228 - question_generation - INFO - Successfully separated 5 questions and 5 answer key items.
2026-01-07 10:33:09,229 - file_utils - INFO - Cleaned up file: D:\Learning Analytics\Learning-AI\Question_and_Answer_Generation\uploads\04-bufferpool.pdf
2026-01-07 10:33:09,230 - pdf_generation - INFO - Creating PDF file: D:\Learning Analytics\Learning-AI\Question_and_Answer_Generation\results\generated_mcqs_04-bufferpool_questions.pdf
2026-01-07 10:33:09,240 - fpdf.output - DEBUG - Final size summary of the biggest document sections:
2026-01-07 10:33:09,241 - fpdf.output - DEBUG - - pages: 1.0KiB
2026-01-07 10:33:09,241 - fpdf.output - DEBUG - - fonts: 199.0B
2026-01-07 10:33:09,241 - pdf_generation - INFO - PDF successfully generated at D:\Learning Analytics\Learning-AI\Question_and_Answer_Generation\results\generated_mcqs_04-bufferpool_questions.pdf
2026-01-07 10:33:09,242 - file_utils - INFO - Saving TXT results for: 04-bufferpool.pdf
2026-01-07 10:33:09,242 - pdf_generation - INFO - Saving merged questions to text file: generated_mcqs_04-bufferpool_key.txt
2026-01-07 10:33:09,243 - pdf_generation - INFO - Successfully saved 5 questions to text file.
2026-01-07 10:33:09,243 - file_utils - INFO - TXT file saved: generated_mcqs_04-bufferpool_key.txt
2026-01-07 10:33:09,243 - routes - INFO - Successfully generated 5 questions.
2026-01-07 10:33:09,246 - httpcore.connection - DEBUG - close.started
2026-01-07 10:33:09,247 - httpcore.connection - DEBUG - close.complete
2026-01-07 10:33:09,247 - httpcore.connection - DEBUG - close.started
2026-01-07 10:33:09,247 - httpcore.connection - DEBUG - close.complete
2026-01-07 10:33:09,248 - httpcore.connection - DEBUG - close.started
2026-01-07 10:33:09,248 - httpcore.connection - DEBUG - close.complete
2026-01-07 10:33:09,244 - routes - ERROR - Error during question generation process: 'score' is undefined
Traceback (most recent call last):
  File "D:\Learning Analytics\Learning-AI\Question_and_Answer_Generation\app\routes.py", line 122, in generate_questions
    return render_template(
        'results.html',
    ...<2 lines>...
        txt_filename=txt_filename # Use txt_filename
    )
  File "D:\Learning Analytics\Learning-AI\Learning_Analytics-API\venv\Lib\site-packages\flask\templating.py", line 150, in render_template
    return _render(app, template, context)
  File "D:\Learning Analytics\Learning-AI\Learning_Analytics-API\venv\Lib\site-packages\flask\templating.py", line 131, in _render
    rv = template.render(context)
  File "D:\Learning Analytics\Learning-AI\Learning_Analytics-API\venv\Lib\site-packages\jinja2\environment.py", line 1295, in render
    self.environment.handle_exception()
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "D:\Learning Analytics\Learning-AI\Learning_Analytics-API\venv\Lib\site-packages\jinja2\environment.py", line 942, in handle_exception
    raise rewrite_traceback_stack(source=source)
  File "D:\Learning Analytics\Learning-AI\Question_and_Answer_Generation\app\templates\results.html", line 154, in top-level template code
    {% set percentage = (score / total * 100) | round %}
    ^^^^^^^^^^^^^
jinja2.exceptions.UndefinedError: 'score' is undefined
2026-01-07 10:33:09,267 - werkzeug - INFO - 127.0.0.1 - - [07/Jan/2026 10:33:09] "[32mPOST /generate HTTP/1.1[0m" 302 -
2026-01-07 10:33:09,277 - routes - INFO - Rendering Question generator page
2026-01-07 10:33:09,278 - werkzeug - INFO - 127.0.0.1 - - [07/Jan/2026 10:33:09] "GET /mcq-generator HTTP/1.1" 200 -
