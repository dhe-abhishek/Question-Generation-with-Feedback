2026-01-21 10:56:32,721 - matplotlib - DEBUG - matplotlib data path: D:\Learning Analytics\Learning-AI\Learning_Analytics-API\venv\Lib\site-packages\matplotlib\mpl-data
2026-01-21 10:56:32,730 - matplotlib - DEBUG - CONFIGDIR=C:\Users\Administrator\.matplotlib
2026-01-21 10:56:32,731 - matplotlib - DEBUG - interactive is False
2026-01-21 10:56:32,731 - matplotlib - DEBUG - platform is win32
2026-01-21 10:56:32,781 - matplotlib - DEBUG - CACHEDIR=C:\Users\Administrator\.matplotlib
2026-01-21 10:56:32,783 - matplotlib.font_manager - DEBUG - Using fontManager instance from C:\Users\Administrator\.matplotlib\fontlist-v390.json
2026-01-21 10:56:35,427 - datasets - DEBUG - PyTorch version 2.9.0 available.
2026-01-21 10:56:38,906 - ragas._analytics - DEBUG - Starting AnalyticsBatcher thread with interval 10 seconds
2026-01-21 10:56:39,879 - relevancy_utils - INFO - Starting Ragas scorer initialization...
2026-01-21 10:56:40,455 - relevancy_utils - DEBUG - ChatGroq LLM initialized.
2026-01-21 10:56:41,888 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cpu
2026-01-21 10:56:41,888 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2026-01-21 10:56:41,890 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): huggingface.co:443
2026-01-21 10:56:42,532 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/modules.json HTTP/1.1" 307 0
2026-01-21 10:56:42,559 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/modules.json HTTP/1.1" 200 0
2026-01-21 10:56:42,787 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/config_sentence_transformers.json HTTP/1.1" 307 0
2026-01-21 10:56:42,811 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config_sentence_transformers.json HTTP/1.1" 200 0
2026-01-21 10:56:43,039 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/config_sentence_transformers.json HTTP/1.1" 307 0
2026-01-21 10:56:43,068 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config_sentence_transformers.json HTTP/1.1" 200 0
2026-01-21 10:56:43,292 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/README.md HTTP/1.1" 307 0
2026-01-21 10:56:43,316 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/README.md HTTP/1.1" 200 0
2026-01-21 10:56:43,542 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/modules.json HTTP/1.1" 307 0
2026-01-21 10:56:43,565 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/modules.json HTTP/1.1" 200 0
2026-01-21 10:56:43,809 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/sentence_bert_config.json HTTP/1.1" 307 0
2026-01-21 10:56:43,836 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/sentence_bert_config.json HTTP/1.1" 200 0
2026-01-21 10:56:44,070 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/adapter_config.json HTTP/1.1" 404 0
2026-01-21 10:56:44,313 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 307 0
2026-01-21 10:56:44,571 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config.json HTTP/1.1" 200 0
2026-01-21 10:56:44,890 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2026-01-21 10:56:44,920 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/tokenizer_config.json HTTP/1.1" 200 0
2026-01-21 10:56:45,175 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "GET /api/models/sentence-transformers/all-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2026-01-21 10:56:45,452 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/1_Pooling/config.json HTTP/1.1" 307 0
2026-01-21 10:56:45,481 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/1_Pooling%2Fconfig.json HTTP/1.1" 200 0
2026-01-21 10:56:45,761 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "GET /api/models/sentence-transformers/all-MiniLM-L6-v2 HTTP/1.1" 200 6828
2026-01-21 10:56:45,769 - relevancy_utils - DEBUG - HuggingFace Embeddings initialized.
2026-01-21 10:56:45,769 - relevancy_utils - INFO - Ragas ResponseRelevancy scorer initialized successfully.
2026-01-21 10:56:45,770 - faithfulness_utils - INFO - Initializing Faithfulness scorer...
2026-01-21 10:56:46,317 - faithfulness_utils - INFO - Faithfulness scorer initialized successfully.
2026-01-21 10:56:46,336 - werkzeug - WARNING -  * Debugger is active!
2026-01-21 10:56:46,338 - werkzeug - INFO -  * Debugger PIN: 103-783-783
2026-01-21 10:56:46,655 - routes - INFO - Rendering home page
2026-01-21 10:56:46,668 - werkzeug - INFO - 127.0.0.1 - - [21/Jan/2026 10:56:46] "GET / HTTP/1.1" 200 -
2026-01-21 10:56:49,201 - routes - INFO - Rendering Question generator page
2026-01-21 10:56:49,208 - werkzeug - INFO - 127.0.0.1 - - [21/Jan/2026 10:56:49] "GET /mcq-generator HTTP/1.1" 200 -
2026-01-21 10:56:55,621 - routes - INFO - Received Question generation request
2026-01-21 10:56:55,630 - validation - INFO - File and parameters validated successfully.
2026-01-21 10:56:55,630 - file_utils - DEBUG - File 13-queryexecution.pdf allowed: True
2026-01-21 10:56:55,636 - file_utils - INFO - File saved to: D:\Learning Analytics\Learning-AI\Question_and_Answer_Generation_with_Feeddack\uploads\13-queryexecution.pdf
2026-01-21 10:56:55,767 - pdf_extraction_util - INFO - Successfully extracted 38407 characters from 13-queryexecution.pdf
2026-01-21 10:56:55,822 - routes - INFO - Successfully saved content for 13-queryexecution.pdf to Context table.
2026-01-21 10:56:56,650 - question_generation - INFO - QuestionGenerator initialized with model: gemini-3-flash-preview
2026-01-21 10:56:56,650 - question_generation - INFO - Generating structured content using model gemini-3-flash-preview...
2026-01-21 10:56:56,650 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2026-01-21 10:56:56,652 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2026-01-21 10:56:56,716 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000014918D83230>
2026-01-21 10:56:56,716 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x0000014918D97D90> server_hostname='generativelanguage.googleapis.com' timeout=None
2026-01-21 10:56:57,091 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000014918DB5950>
2026-01-21 10:56:57,092 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2026-01-21 10:56:57,092 - httpcore.http11 - DEBUG - send_request_headers.complete
2026-01-21 10:56:57,093 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2026-01-21 10:56:57,093 - httpcore.http11 - DEBUG - send_request_body.complete
2026-01-21 10:56:57,093 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2026-01-21 10:57:20,061 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Wed, 21 Jan 2026 05:27:20 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=22946'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2026-01-21 10:57:20,062 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-3-flash-preview:generateContent "HTTP/1.1 200 OK"
2026-01-21 10:57:20,062 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2026-01-21 10:57:20,102 - httpcore.http11 - DEBUG - receive_response_body.complete
2026-01-21 10:57:20,102 - httpcore.http11 - DEBUG - response_closed.started
2026-01-21 10:57:20,102 - httpcore.http11 - DEBUG - response_closed.complete
2026-01-21 10:57:20,106 - google_genai.types - WARNING - Warning: there are non-text parts in the response: ['thought_signature'], returning concatenated parsed result from text parts. Check the full candidates.content.parts accessor to get the full model response.
2026-01-21 10:57:20,107 - google_genai.types - WARNING - Warning: there are non-text parts in the response: ['thought_signature'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.
2026-01-21 10:57:20,108 - question_generation - INFO - Successfully separated 5 questions and 5 answer key items.
2026-01-21 10:57:20,109 - file_utils - INFO - Cleaned up file: D:\Learning Analytics\Learning-AI\Question_and_Answer_Generation_with_Feeddack\uploads\13-queryexecution.pdf
2026-01-21 10:57:20,109 - pdf_generation - INFO - Creating PDF file: D:\Learning Analytics\Learning-AI\Question_and_Answer_Generation_with_Feeddack\results\generated_mcqs_13-queryexecution_questions.pdf
2026-01-21 10:57:20,134 - fpdf.fpdf - DEBUG - Page break on page 1 at y=272 for element of height 6 > 277
2026-01-21 10:57:20,145 - fpdf.output - DEBUG - Final size summary of the biggest document sections:
2026-01-21 10:57:20,145 - fpdf.output - DEBUG - - pages: 2.8KiB
2026-01-21 10:57:20,145 - fpdf.output - DEBUG - - fonts: 304.0B
2026-01-21 10:57:20,146 - pdf_generation - INFO - PDF successfully generated at D:\Learning Analytics\Learning-AI\Question_and_Answer_Generation_with_Feeddack\results\generated_mcqs_13-queryexecution_questions.pdf
2026-01-21 10:57:20,147 - file_utils - INFO - Saving TXT results for: 13-queryexecution.pdf
2026-01-21 10:57:20,147 - pdf_generation - INFO - Saving merged questions to text file: generated_mcqs_13-queryexecution_key.txt
2026-01-21 10:57:20,149 - pdf_generation - INFO - Successfully saved 5 questions to text file.
2026-01-21 10:57:20,149 - file_utils - INFO - TXT file saved: generated_mcqs_13-queryexecution_key.txt
2026-01-21 10:57:20,149 - routes - INFO - Successfully generated 5 questions.
2026-01-21 10:57:20,162 - httpcore.connection - DEBUG - close.started
2026-01-21 10:57:20,162 - httpcore.connection - DEBUG - close.complete
2026-01-21 10:57:20,172 - werkzeug - INFO - 127.0.0.1 - - [21/Jan/2026 10:57:20] "POST /generate HTTP/1.1" 200 -
2026-01-21 10:58:38,793 - routes - INFO - Download request for: generated_mcqs_13-queryexecution_questions.pdf
2026-01-21 10:58:38,793 - routes - INFO - Sending file: D:\Learning Analytics\Learning-AI\Question_and_Answer_Generation_with_Feeddack\results\generated_mcqs_13-queryexecution_questions.pdf
2026-01-21 10:58:38,794 - werkzeug - INFO - 127.0.0.1 - - [21/Jan/2026 10:58:38] "GET /download/generated_mcqs_13-queryexecution_questions.pdf HTTP/1.1" 200 -
2026-01-21 10:59:18,991 - question_generation - INFO - QuestionGenerator initialized with model: gemini-3-flash-preview
2026-01-21 10:59:18,995 - question_generation - INFO - Generating structured content using model gemini-3-flash-preview...
2026-01-21 10:59:18,999 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2026-01-21 10:59:19,004 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2026-01-21 10:59:19,024 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000014918D0C910>
2026-01-21 10:59:19,024 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x0000014918D7ADF0> server_hostname='generativelanguage.googleapis.com' timeout=None
2026-01-21 10:59:19,044 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000014918DE3950>
2026-01-21 10:59:19,045 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2026-01-21 10:59:19,045 - httpcore.http11 - DEBUG - send_request_headers.complete
2026-01-21 10:59:19,045 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2026-01-21 10:59:19,045 - httpcore.http11 - DEBUG - send_request_body.complete
2026-01-21 10:59:19,046 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2026-01-21 11:00:04,667 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Wed, 21 Jan 2026 05:30:04 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=45605'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2026-01-21 11:00:04,668 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-3-flash-preview:generateContent "HTTP/1.1 200 OK"
2026-01-21 11:00:04,669 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2026-01-21 11:00:04,670 - httpcore.http11 - DEBUG - receive_response_body.complete
2026-01-21 11:00:04,670 - httpcore.http11 - DEBUG - response_closed.started
2026-01-21 11:00:04,670 - httpcore.http11 - DEBUG - response_closed.complete
2026-01-21 11:00:04,672 - google_genai.types - WARNING - Warning: there are non-text parts in the response: ['thought_signature'], returning concatenated parsed result from text parts. Check the full candidates.content.parts accessor to get the full model response.
2026-01-21 11:00:04,672 - google_genai.types - WARNING - Warning: there are non-text parts in the response: ['thought_signature'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.
2026-01-21 11:00:04,673 - pdf_generation - INFO - Creating PDF file: D:\Learning Analytics\Learning-AI\Question_and_Answer_Generation_with_Feeddack\results\generated_mcqs_13-queryexecution_questions.pdf
2026-01-21 11:00:04,688 - fpdf.fpdf - DEBUG - Page break on page 1 at y=277 for element of height 6 > 277
2026-01-21 11:00:04,698 - fpdf.output - DEBUG - Final size summary of the biggest document sections:
2026-01-21 11:00:04,698 - fpdf.output - DEBUG - - pages: 2.8KiB
2026-01-21 11:00:04,698 - fpdf.output - DEBUG - - fonts: 304.0B
2026-01-21 11:00:04,699 - pdf_generation - INFO - PDF successfully generated at D:\Learning Analytics\Learning-AI\Question_and_Answer_Generation_with_Feeddack\results\generated_mcqs_13-queryexecution_questions.pdf
2026-01-21 11:00:04,699 - file_utils - INFO - Saving TXT results for: 13-queryexecution.pdf
2026-01-21 11:00:04,700 - pdf_generation - INFO - Saving merged questions to text file: generated_mcqs_13-queryexecution_key.txt
2026-01-21 11:00:04,703 - pdf_generation - INFO - Successfully saved 5 questions to text file.
2026-01-21 11:00:04,703 - file_utils - INFO - TXT file saved: generated_mcqs_13-queryexecution_key.txt
2026-01-21 11:00:04,704 - httpcore.connection - DEBUG - close.started
2026-01-21 11:00:04,704 - httpcore.connection - DEBUG - close.complete
2026-01-21 11:00:04,709 - werkzeug - INFO - 127.0.0.1 - - [21/Jan/2026 11:00:04] "POST /reframe_question HTTP/1.1" 200 -
2026-01-21 11:00:14,935 - routes - INFO - Received Question generation request
2026-01-21 11:00:14,943 - validation - INFO - File and parameters validated successfully.
2026-01-21 11:00:14,944 - file_utils - DEBUG - File 13-queryexecution.pdf allowed: True
2026-01-21 11:00:14,948 - file_utils - INFO - File saved to: D:\Learning Analytics\Learning-AI\Question_and_Answer_Generation_with_Feeddack\uploads\13-queryexecution.pdf
2026-01-21 11:00:15,111 - pdf_extraction_util - INFO - Successfully extracted 38407 characters from 13-queryexecution.pdf
2026-01-21 11:00:15,119 - routes - INFO - Successfully saved content for 13-queryexecution.pdf to Context table.
2026-01-21 11:00:15,943 - question_generation - INFO - QuestionGenerator initialized with model: gemini-3-flash-preview
2026-01-21 11:00:15,944 - question_generation - INFO - Generating structured content using model gemini-3-flash-preview...
2026-01-21 11:00:15,944 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2026-01-21 11:00:15,945 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2026-01-21 11:00:15,964 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000014918D00180>
2026-01-21 11:00:15,965 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x0000014918D08550> server_hostname='generativelanguage.googleapis.com' timeout=None
2026-01-21 11:00:15,987 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000014918BAF770>
2026-01-21 11:00:15,987 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2026-01-21 11:00:15,988 - httpcore.http11 - DEBUG - send_request_headers.complete
2026-01-21 11:00:15,988 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2026-01-21 11:00:15,988 - httpcore.http11 - DEBUG - send_request_body.complete
2026-01-21 11:00:15,988 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2026-01-21 11:00:30,999 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Wed, 21 Jan 2026 05:30:30 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=14999'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2026-01-21 11:00:30,999 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-3-flash-preview:generateContent "HTTP/1.1 200 OK"
2026-01-21 11:00:30,999 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2026-01-21 11:00:31,001 - httpcore.http11 - DEBUG - receive_response_body.complete
2026-01-21 11:00:31,001 - httpcore.http11 - DEBUG - response_closed.started
2026-01-21 11:00:31,001 - httpcore.http11 - DEBUG - response_closed.complete
2026-01-21 11:00:31,002 - google_genai.types - WARNING - Warning: there are non-text parts in the response: ['thought_signature'], returning concatenated parsed result from text parts. Check the full candidates.content.parts accessor to get the full model response.
2026-01-21 11:00:31,003 - google_genai.types - WARNING - Warning: there are non-text parts in the response: ['thought_signature'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.
2026-01-21 11:00:31,003 - question_generation - INFO - Successfully separated 5 questions and 5 answer key items.
2026-01-21 11:00:31,004 - file_utils - INFO - Cleaned up file: D:\Learning Analytics\Learning-AI\Question_and_Answer_Generation_with_Feeddack\uploads\13-queryexecution.pdf
2026-01-21 11:00:31,004 - pdf_generation - INFO - Creating PDF file: D:\Learning Analytics\Learning-AI\Question_and_Answer_Generation_with_Feeddack\results\generated_mcqs_13-queryexecution_questions.pdf
2026-01-21 11:00:31,011 - fpdf.fpdf - DEBUG - Page break on page 1 at y=283 for element of height 6 > 277
2026-01-21 11:00:31,020 - fpdf.output - DEBUG - Final size summary of the biggest document sections:
2026-01-21 11:00:31,020 - fpdf.output - DEBUG - - pages: 2.3KiB
2026-01-21 11:00:31,020 - fpdf.output - DEBUG - - fonts: 304.0B
2026-01-21 11:00:31,020 - pdf_generation - INFO - PDF successfully generated at D:\Learning Analytics\Learning-AI\Question_and_Answer_Generation_with_Feeddack\results\generated_mcqs_13-queryexecution_questions.pdf
2026-01-21 11:00:31,021 - file_utils - INFO - Saving TXT results for: 13-queryexecution.pdf
2026-01-21 11:00:31,023 - pdf_generation - INFO - Saving merged questions to text file: generated_mcqs_13-queryexecution_key.txt
2026-01-21 11:00:31,024 - pdf_generation - INFO - Successfully saved 5 questions to text file.
2026-01-21 11:00:31,024 - file_utils - INFO - TXT file saved: generated_mcqs_13-queryexecution_key.txt
2026-01-21 11:00:31,024 - routes - INFO - Successfully generated 5 questions.
2026-01-21 11:00:31,026 - httpcore.connection - DEBUG - close.started
2026-01-21 11:00:31,027 - httpcore.connection - DEBUG - close.complete
2026-01-21 11:00:31,033 - werkzeug - INFO - 127.0.0.1 - - [21/Jan/2026 11:00:31] "POST /generate HTTP/1.1" 200 -
2026-01-21 11:00:37,013 - routes - INFO - Download request for: generated_mcqs_13-queryexecution_questions.pdf
2026-01-21 11:00:37,013 - routes - INFO - Sending file: D:\Learning Analytics\Learning-AI\Question_and_Answer_Generation_with_Feeddack\results\generated_mcqs_13-queryexecution_questions.pdf
2026-01-21 11:00:37,015 - werkzeug - INFO - 127.0.0.1 - - [21/Jan/2026 11:00:37] "GET /download/generated_mcqs_13-queryexecution_questions.pdf HTTP/1.1" 200 -
2026-01-21 11:02:06,261 - routes - INFO - Rendering home page
2026-01-21 11:02:06,262 - werkzeug - INFO - 127.0.0.1 - - [21/Jan/2026 11:02:06] "GET / HTTP/1.1" 200 -
2026-01-21 11:02:08,547 - routes - INFO - Rendering Question generator page
2026-01-21 11:02:08,548 - werkzeug - INFO - 127.0.0.1 - - [21/Jan/2026 11:02:08] "GET /mcq-generator HTTP/1.1" 200 -
2026-01-21 11:02:15,672 - routes - INFO - Received Question generation request
2026-01-21 11:02:15,687 - validation - INFO - File and parameters validated successfully.
2026-01-21 11:02:15,687 - file_utils - DEBUG - File 13-queryexecution.pdf allowed: True
2026-01-21 11:02:15,691 - file_utils - INFO - File saved to: D:\Learning Analytics\Learning-AI\Question_and_Answer_Generation_with_Feeddack\uploads\13-queryexecution.pdf
2026-01-21 11:02:15,827 - pdf_extraction_util - INFO - Successfully extracted 38407 characters from 13-queryexecution.pdf
2026-01-21 11:02:15,840 - routes - INFO - Successfully saved content for 13-queryexecution.pdf to Context table.
2026-01-21 11:02:16,719 - question_generation - INFO - QuestionGenerator initialized with model: gemini-3-flash-preview
2026-01-21 11:02:16,720 - question_generation - INFO - Generating structured content using model gemini-3-flash-preview...
2026-01-21 11:02:16,720 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2026-01-21 11:02:16,722 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2026-01-21 11:02:16,751 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000014918CFD150>
2026-01-21 11:02:16,752 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x0000014918D09090> server_hostname='generativelanguage.googleapis.com' timeout=None
2026-01-21 11:02:16,769 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000014918CFD480>
2026-01-21 11:02:16,770 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2026-01-21 11:02:16,770 - httpcore.http11 - DEBUG - send_request_headers.complete
2026-01-21 11:02:16,770 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2026-01-21 11:02:16,771 - httpcore.http11 - DEBUG - send_request_body.complete
2026-01-21 11:02:16,771 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2026-01-21 11:02:32,062 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Wed, 21 Jan 2026 05:32:32 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=15279'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2026-01-21 11:02:32,062 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-3-flash-preview:generateContent "HTTP/1.1 200 OK"
2026-01-21 11:02:32,062 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2026-01-21 11:02:32,063 - httpcore.http11 - DEBUG - receive_response_body.complete
2026-01-21 11:02:32,063 - httpcore.http11 - DEBUG - response_closed.started
2026-01-21 11:02:32,063 - httpcore.http11 - DEBUG - response_closed.complete
2026-01-21 11:02:32,064 - google_genai.types - WARNING - Warning: there are non-text parts in the response: ['thought_signature'], returning concatenated parsed result from text parts. Check the full candidates.content.parts accessor to get the full model response.
2026-01-21 11:02:32,064 - google_genai.types - WARNING - Warning: there are non-text parts in the response: ['thought_signature'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.
2026-01-21 11:02:32,065 - question_generation - INFO - Successfully separated 5 questions and 5 answer key items.
2026-01-21 11:02:32,067 - file_utils - INFO - Cleaned up file: D:\Learning Analytics\Learning-AI\Question_and_Answer_Generation_with_Feeddack\uploads\13-queryexecution.pdf
2026-01-21 11:02:32,067 - pdf_generation - INFO - Creating PDF file: D:\Learning Analytics\Learning-AI\Question_and_Answer_Generation_with_Feeddack\results\generated_mcqs_13-queryexecution_questions.pdf
2026-01-21 11:02:32,078 - fpdf.fpdf - DEBUG - Page break on page 1 at y=277 for element of height 6 > 277
2026-01-21 11:02:32,090 - fpdf.output - DEBUG - Final size summary of the biggest document sections:
2026-01-21 11:02:32,090 - fpdf.output - DEBUG - - pages: 2.4KiB
2026-01-21 11:02:32,090 - fpdf.output - DEBUG - - fonts: 304.0B
2026-01-21 11:02:32,091 - pdf_generation - INFO - PDF successfully generated at D:\Learning Analytics\Learning-AI\Question_and_Answer_Generation_with_Feeddack\results\generated_mcqs_13-queryexecution_questions.pdf
2026-01-21 11:02:32,091 - file_utils - INFO - Saving TXT results for: 13-queryexecution.pdf
2026-01-21 11:02:32,092 - pdf_generation - INFO - Saving merged questions to text file: generated_mcqs_13-queryexecution_key.txt
2026-01-21 11:02:32,093 - pdf_generation - INFO - Successfully saved 5 questions to text file.
2026-01-21 11:02:32,093 - file_utils - INFO - TXT file saved: generated_mcqs_13-queryexecution_key.txt
2026-01-21 11:02:32,093 - routes - INFO - Successfully generated 5 questions.
2026-01-21 11:02:32,093 - httpcore.connection - DEBUG - close.started
2026-01-21 11:02:32,094 - httpcore.connection - DEBUG - close.complete
2026-01-21 11:02:32,098 - werkzeug - INFO - 127.0.0.1 - - [21/Jan/2026 11:02:32] "POST /generate HTTP/1.1" 200 -
2026-01-21 11:10:29,830 - werkzeug - INFO -  * Detected change in 'D:\\Learning Analytics\\Learning-AI\\Question_and_Answer_Generation_with_Feeddack\\app\\routes.py', reloading
2026-01-21 11:10:29,831 - ragas._analytics - DEBUG - AnalyticsBatcher shutdown complete
