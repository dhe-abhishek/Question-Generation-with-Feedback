2026-01-22 14:16:18,855 - matplotlib - DEBUG - matplotlib data path: D:\Learning Analytics\Learning-AI\Learning_Analytics-API\venv\Lib\site-packages\matplotlib\mpl-data
2026-01-22 14:16:18,861 - matplotlib - DEBUG - CONFIGDIR=C:\Users\Administrator\.matplotlib
2026-01-22 14:16:18,861 - matplotlib - DEBUG - interactive is False
2026-01-22 14:16:18,861 - matplotlib - DEBUG - platform is win32
2026-01-22 14:16:18,888 - matplotlib - DEBUG - CACHEDIR=C:\Users\Administrator\.matplotlib
2026-01-22 14:16:18,890 - matplotlib.font_manager - DEBUG - Using fontManager instance from C:\Users\Administrator\.matplotlib\fontlist-v390.json
2026-01-22 14:16:20,274 - datasets - DEBUG - PyTorch version 2.9.0 available.
2026-01-22 14:16:21,981 - ragas._analytics - DEBUG - Starting AnalyticsBatcher thread with interval 10 seconds
2026-01-22 14:16:22,485 - relevancy_utils - INFO - Starting Ragas scorer initialization...
2026-01-22 14:16:22,809 - relevancy_utils - DEBUG - ChatGroq LLM initialized.
2026-01-22 14:16:23,588 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cpu
2026-01-22 14:16:23,588 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2026-01-22 14:16:23,589 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): huggingface.co:443
2026-01-22 14:16:24,006 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/modules.json HTTP/1.1" 307 0
2026-01-22 14:16:24,024 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/modules.json HTTP/1.1" 200 0
2026-01-22 14:16:24,247 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/config_sentence_transformers.json HTTP/1.1" 307 0
2026-01-22 14:16:24,267 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config_sentence_transformers.json HTTP/1.1" 200 0
2026-01-22 14:16:24,504 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/config_sentence_transformers.json HTTP/1.1" 307 0
2026-01-22 14:16:24,521 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config_sentence_transformers.json HTTP/1.1" 200 0
2026-01-22 14:16:24,754 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/README.md HTTP/1.1" 307 0
2026-01-22 14:16:24,772 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/README.md HTTP/1.1" 200 0
2026-01-22 14:16:24,993 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/modules.json HTTP/1.1" 307 0
2026-01-22 14:16:25,013 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/modules.json HTTP/1.1" 200 0
2026-01-22 14:16:25,250 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/sentence_bert_config.json HTTP/1.1" 307 0
2026-01-22 14:16:25,269 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/sentence_bert_config.json HTTP/1.1" 200 0
2026-01-22 14:16:25,492 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/adapter_config.json HTTP/1.1" 404 0
2026-01-22 14:16:25,713 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 307 0
2026-01-22 14:16:25,738 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config.json HTTP/1.1" 200 0
2026-01-22 14:16:26,020 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2026-01-22 14:16:26,044 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/tokenizer_config.json HTTP/1.1" 200 0
2026-01-22 14:16:26,282 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "GET /api/models/sentence-transformers/all-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2026-01-22 14:16:26,532 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/1_Pooling/config.json HTTP/1.1" 307 0
2026-01-22 14:16:26,551 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/1_Pooling%2Fconfig.json HTTP/1.1" 200 0
2026-01-22 14:16:26,772 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "GET /api/models/sentence-transformers/all-MiniLM-L6-v2 HTTP/1.1" 200 6837
2026-01-22 14:16:26,774 - relevancy_utils - DEBUG - HuggingFace Embeddings initialized.
2026-01-22 14:16:26,774 - relevancy_utils - INFO - Ragas ResponseRelevancy scorer initialized successfully.
2026-01-22 14:16:26,775 - faithfulness_utils - INFO - Initializing Faithfulness scorer...
2026-01-22 14:16:27,064 - faithfulness_utils - INFO - Faithfulness scorer initialized successfully.
2026-01-22 14:16:27,072 - werkzeug - WARNING -  * Debugger is active!
2026-01-22 14:16:27,073 - werkzeug - INFO -  * Debugger PIN: 103-783-783
2026-01-22 14:21:34,399 - routes - INFO - Rendering home page
2026-01-22 14:21:34,420 - werkzeug - INFO - 127.0.0.1 - - [22/Jan/2026 14:21:34] "GET / HTTP/1.1" 200 -
2026-01-22 14:21:36,877 - routes - INFO - Rendering Question generator page
2026-01-22 14:21:36,880 - werkzeug - INFO - 127.0.0.1 - - [22/Jan/2026 14:21:36] "GET /mcq-generator HTTP/1.1" 200 -
2026-01-22 14:21:45,539 - routes - INFO - Received Question generation request
2026-01-22 14:21:45,553 - validation - INFO - File and parameters validated successfully.
2026-01-22 14:21:45,553 - file_utils - DEBUG - File 13-queryexecution.pdf allowed: True
2026-01-22 14:21:45,558 - file_utils - INFO - File saved to: D:\Learning Analytics\Learning-AI\Question_and_Answer_Generation_with_Feeddack\uploads\13-queryexecution.pdf
2026-01-22 14:21:45,687 - pdf_extraction_util - INFO - Successfully extracted 38407 characters from 13-queryexecution.pdf
2026-01-22 14:21:45,740 - routes - INFO - Successfully saved content for 13-queryexecution.pdf to Context table.
2026-01-22 14:21:46,712 - question_generation - INFO - QuestionGenerator initialized with model: gemini-3-flash-preview
2026-01-22 14:21:46,713 - question_generation - INFO - Generating structured content using model gemini-3-flash-preview...
2026-01-22 14:21:46,714 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2026-01-22 14:21:46,717 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2026-01-22 14:21:46,749 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002BEC95BF230>
2026-01-22 14:21:46,749 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000002BEC95CFB10> server_hostname='generativelanguage.googleapis.com' timeout=None
2026-01-22 14:21:46,773 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002BEC95C1310>
2026-01-22 14:21:46,773 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2026-01-22 14:21:46,774 - httpcore.http11 - DEBUG - send_request_headers.complete
2026-01-22 14:21:46,774 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2026-01-22 14:21:46,774 - httpcore.http11 - DEBUG - send_request_body.complete
2026-01-22 14:21:46,775 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2026-01-22 14:22:04,751 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 22 Jan 2026 08:52:04 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=17958'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2026-01-22 14:22:04,751 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-3-flash-preview:generateContent "HTTP/1.1 200 OK"
2026-01-22 14:22:04,751 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2026-01-22 14:22:04,753 - httpcore.http11 - DEBUG - receive_response_body.complete
2026-01-22 14:22:04,753 - httpcore.http11 - DEBUG - response_closed.started
2026-01-22 14:22:04,754 - httpcore.http11 - DEBUG - response_closed.complete
2026-01-22 14:22:04,754 - google_genai.types - WARNING - Warning: there are non-text parts in the response: ['thought_signature'], returning concatenated parsed result from text parts. Check the full candidates.content.parts accessor to get the full model response.
2026-01-22 14:22:04,755 - google_genai.types - WARNING - Warning: there are non-text parts in the response: ['thought_signature'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.
2026-01-22 14:22:04,755 - question_generation - INFO - Successfully separated 5 questions and 5 answer key items.
2026-01-22 14:22:04,759 - file_utils - INFO - Cleaned up file: D:\Learning Analytics\Learning-AI\Question_and_Answer_Generation_with_Feeddack\uploads\13-queryexecution.pdf
2026-01-22 14:22:04,759 - pdf_generation - INFO - Creating PDF file: D:\Learning Analytics\Learning-AI\Question_and_Answer_Generation_with_Feeddack\results\generated_mcqs_13-queryexecution_questions.pdf
2026-01-22 14:22:04,777 - fpdf.output - DEBUG - Final size summary of the biggest document sections:
2026-01-22 14:22:04,777 - fpdf.output - DEBUG - - pages: 1.2KiB
2026-01-22 14:22:04,777 - fpdf.output - DEBUG - - fonts: 199.0B
2026-01-22 14:22:04,778 - pdf_generation - INFO - PDF successfully generated at D:\Learning Analytics\Learning-AI\Question_and_Answer_Generation_with_Feeddack\results\generated_mcqs_13-queryexecution_questions.pdf
2026-01-22 14:22:04,778 - file_utils - INFO - Saving TXT results for: 13-queryexecution.pdf
2026-01-22 14:22:04,781 - pdf_generation - INFO - Saving merged questions to text file: generated_mcqs_13-queryexecution_key.txt
2026-01-22 14:22:04,783 - pdf_generation - INFO - Successfully saved 5 questions to text file.
2026-01-22 14:22:04,783 - file_utils - INFO - TXT file saved: generated_mcqs_13-queryexecution_key.txt
2026-01-22 14:22:04,787 - routes - INFO - Successfully generated 5 questions.
2026-01-22 14:22:04,803 - httpcore.connection - DEBUG - close.started
2026-01-22 14:22:04,806 - httpcore.connection - DEBUG - close.complete
2026-01-22 14:22:04,813 - werkzeug - INFO - 127.0.0.1 - - [22/Jan/2026 14:22:04] "POST /generate HTTP/1.1" 200 -
2026-01-22 14:22:22,568 - question_generation - INFO - QuestionGenerator initialized with model: gemini-3-flash-preview
2026-01-22 14:22:22,569 - question_generation - INFO - Generating structured content using model gemini-3-flash-preview...
2026-01-22 14:22:22,569 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2026-01-22 14:22:22,571 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2026-01-22 14:22:22,590 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002BEC95C3ED0>
2026-01-22 14:22:22,590 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000002BEC95AC4B0> server_hostname='generativelanguage.googleapis.com' timeout=None
2026-01-22 14:22:22,612 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002BEC9613230>
2026-01-22 14:22:22,613 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2026-01-22 14:22:22,613 - httpcore.http11 - DEBUG - send_request_headers.complete
2026-01-22 14:22:22,613 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2026-01-22 14:22:22,614 - httpcore.http11 - DEBUG - send_request_body.complete
2026-01-22 14:22:22,614 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2026-01-22 14:22:31,708 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 22 Jan 2026 08:52:31 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=9077'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2026-01-22 14:22:31,709 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-3-flash-preview:generateContent "HTTP/1.1 200 OK"
2026-01-22 14:22:31,709 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2026-01-22 14:22:31,710 - httpcore.http11 - DEBUG - receive_response_body.complete
2026-01-22 14:22:31,710 - httpcore.http11 - DEBUG - response_closed.started
2026-01-22 14:22:31,710 - httpcore.http11 - DEBUG - response_closed.complete
2026-01-22 14:22:31,712 - google_genai.types - WARNING - Warning: there are non-text parts in the response: ['thought_signature'], returning concatenated parsed result from text parts. Check the full candidates.content.parts accessor to get the full model response.
2026-01-22 14:22:31,712 - google_genai.types - WARNING - Warning: there are non-text parts in the response: ['thought_signature'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.
2026-01-22 14:22:31,712 - pdf_generation - INFO - Creating PDF file: D:\Learning Analytics\Learning-AI\Question_and_Answer_Generation_with_Feeddack\results\generated_mcqs_13-queryexecution_questions.pdf
2026-01-22 14:22:31,717 - fpdf.output - DEBUG - Final size summary of the biggest document sections:
2026-01-22 14:22:31,717 - fpdf.output - DEBUG - - pages: 1.1KiB
2026-01-22 14:22:31,717 - fpdf.output - DEBUG - - fonts: 199.0B
2026-01-22 14:22:31,718 - pdf_generation - INFO - PDF successfully generated at D:\Learning Analytics\Learning-AI\Question_and_Answer_Generation_with_Feeddack\results\generated_mcqs_13-queryexecution_questions.pdf
2026-01-22 14:22:31,718 - file_utils - INFO - Saving TXT results for: 13-queryexecution.pdf
2026-01-22 14:22:31,719 - pdf_generation - INFO - Saving merged questions to text file: generated_mcqs_13-queryexecution_key.txt
2026-01-22 14:22:31,720 - pdf_generation - INFO - Successfully saved 4 questions to text file.
2026-01-22 14:22:31,720 - file_utils - INFO - TXT file saved: generated_mcqs_13-queryexecution_key.txt
2026-01-22 14:22:31,721 - httpcore.connection - DEBUG - close.started
2026-01-22 14:22:31,722 - httpcore.connection - DEBUG - close.complete
2026-01-22 14:22:31,727 - werkzeug - INFO - 127.0.0.1 - - [22/Jan/2026 14:22:31] "POST /reframe_question HTTP/1.1" 200 -
2026-01-22 14:22:31,735 - routes - INFO - Display Results Called
2026-01-22 14:22:31,739 - werkzeug - INFO - 127.0.0.1 - - [22/Jan/2026 14:22:31] "GET /display_results HTTP/1.1" 200 -
2026-01-22 14:22:40,785 - routes - INFO - Download request for: 13-queryexecution.pdf.pdf
2026-01-22 14:22:40,786 - routes - ERROR - File not found or invalid path: D:\Learning Analytics\Learning-AI\Question_and_Answer_Generation_with_Feeddack\results\13-queryexecution.pdf.pdf
2026-01-22 14:22:40,788 - werkzeug - INFO - 127.0.0.1 - - [22/Jan/2026 14:22:40] "[32mGET /download/13-queryexecution.pdf.pdf HTTP/1.1[0m" 302 -
2026-01-22 14:22:40,794 - routes - INFO - Rendering Question generator page
2026-01-22 14:22:40,795 - werkzeug - INFO - 127.0.0.1 - - [22/Jan/2026 14:22:40] "GET /mcq-generator HTTP/1.1" 200 -
2026-01-22 14:23:09,511 - question_generation - INFO - QuestionGenerator initialized with model: gemini-3-flash-preview
2026-01-22 14:23:09,511 - question_generation - WARNING - Unsupported question type: . Defaulting to MCQ schema.
2026-01-22 14:23:09,512 - question_generation - INFO - Generating structured content using model gemini-3-flash-preview...
2026-01-22 14:23:09,512 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2026-01-22 14:23:09,513 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2026-01-22 14:23:09,531 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002BEC953C050>
2026-01-22 14:23:09,531 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000002BEC95AFC50> server_hostname='generativelanguage.googleapis.com' timeout=None
2026-01-22 14:23:09,553 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002BEC96272F0>
2026-01-22 14:23:09,553 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2026-01-22 14:23:09,554 - httpcore.http11 - DEBUG - send_request_headers.complete
2026-01-22 14:23:09,554 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2026-01-22 14:23:09,554 - httpcore.http11 - DEBUG - send_request_body.complete
2026-01-22 14:23:09,554 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2026-01-22 14:23:16,367 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 22 Jan 2026 08:53:16 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=6796'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2026-01-22 14:23:16,368 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-3-flash-preview:generateContent "HTTP/1.1 200 OK"
2026-01-22 14:23:16,369 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2026-01-22 14:23:16,371 - httpcore.http11 - DEBUG - receive_response_body.complete
2026-01-22 14:23:16,371 - httpcore.http11 - DEBUG - response_closed.started
2026-01-22 14:23:16,371 - httpcore.http11 - DEBUG - response_closed.complete
2026-01-22 14:23:16,372 - google_genai.types - WARNING - Warning: there are non-text parts in the response: ['thought_signature'], returning concatenated parsed result from text parts. Check the full candidates.content.parts accessor to get the full model response.
2026-01-22 14:23:16,373 - google_genai.types - WARNING - Warning: there are non-text parts in the response: ['thought_signature'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.
2026-01-22 14:23:16,373 - pdf_generation - INFO - Creating PDF file: D:\Learning Analytics\Learning-AI\Question_and_Answer_Generation_with_Feeddack\results\generated_mcqs_13-queryexecution_questions.pdf
2026-01-22 14:23:16,384 - fpdf.output - DEBUG - Final size summary of the biggest document sections:
2026-01-22 14:23:16,384 - fpdf.output - DEBUG - - pages: 1.0KiB
2026-01-22 14:23:16,384 - fpdf.output - DEBUG - - fonts: 199.0B
2026-01-22 14:23:16,385 - pdf_generation - INFO - PDF successfully generated at D:\Learning Analytics\Learning-AI\Question_and_Answer_Generation_with_Feeddack\results\generated_mcqs_13-queryexecution_questions.pdf
2026-01-22 14:23:16,385 - file_utils - INFO - Saving TXT results for: 13-queryexecution.pdf
2026-01-22 14:23:16,386 - pdf_generation - INFO - Saving merged questions to text file: generated_mcqs_13-queryexecution_key.txt
2026-01-22 14:23:16,387 - pdf_generation - INFO - Successfully saved 4 questions to text file.
2026-01-22 14:23:16,387 - file_utils - INFO - TXT file saved: generated_mcqs_13-queryexecution_key.txt
2026-01-22 14:23:16,388 - httpcore.connection - DEBUG - close.started
2026-01-22 14:23:16,388 - httpcore.connection - DEBUG - close.complete
2026-01-22 14:23:16,394 - werkzeug - INFO - 127.0.0.1 - - [22/Jan/2026 14:23:16] "POST /reframe_question HTTP/1.1" 200 -
2026-01-22 14:23:16,403 - routes - INFO - Display Results Called
2026-01-22 14:23:16,406 - werkzeug - INFO - 127.0.0.1 - - [22/Jan/2026 14:23:16] "GET /display_results HTTP/1.1" 200 -
2026-01-22 14:26:37,593 - routes - INFO - Rendering home page
2026-01-22 14:26:37,594 - werkzeug - INFO - 127.0.0.1 - - [22/Jan/2026 14:26:37] "GET / HTTP/1.1" 200 -
2026-01-22 14:26:40,140 - routes - INFO - Rendering Question generator page
2026-01-22 14:26:40,141 - werkzeug - INFO - 127.0.0.1 - - [22/Jan/2026 14:26:40] "GET /mcq-generator HTTP/1.1" 200 -
2026-01-22 14:26:48,569 - routes - INFO - Received Question generation request
2026-01-22 14:26:48,578 - validation - INFO - File and parameters validated successfully.
2026-01-22 14:26:48,579 - file_utils - DEBUG - File 13-queryexecution.pdf allowed: True
2026-01-22 14:26:48,585 - file_utils - INFO - File saved to: D:\Learning Analytics\Learning-AI\Question_and_Answer_Generation_with_Feeddack\uploads\13-queryexecution.pdf
2026-01-22 14:26:48,723 - pdf_extraction_util - INFO - Successfully extracted 38407 characters from 13-queryexecution.pdf
2026-01-22 14:26:48,730 - routes - INFO - Successfully saved content for 13-queryexecution.pdf to Context table.
2026-01-22 14:26:49,557 - question_generation - INFO - QuestionGenerator initialized with model: gemini-3-flash-preview
2026-01-22 14:26:49,557 - question_generation - INFO - Generating structured content using model gemini-3-flash-preview...
2026-01-22 14:26:49,558 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2026-01-22 14:26:49,560 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2026-01-22 14:26:49,591 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002BEC8473CE0>
2026-01-22 14:26:49,591 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000002BEC9538370> server_hostname='generativelanguage.googleapis.com' timeout=None
2026-01-22 14:26:49,615 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002BEC8473F00>
2026-01-22 14:26:49,615 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2026-01-22 14:26:49,616 - httpcore.http11 - DEBUG - send_request_headers.complete
2026-01-22 14:26:49,616 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2026-01-22 14:26:49,616 - httpcore.http11 - DEBUG - send_request_body.complete
2026-01-22 14:26:49,616 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2026-01-22 14:27:00,249 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 22 Jan 2026 08:57:00 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=10615'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2026-01-22 14:27:00,249 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-3-flash-preview:generateContent "HTTP/1.1 200 OK"
2026-01-22 14:27:00,250 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2026-01-22 14:27:00,251 - httpcore.http11 - DEBUG - receive_response_body.complete
2026-01-22 14:27:00,251 - httpcore.http11 - DEBUG - response_closed.started
2026-01-22 14:27:00,251 - httpcore.http11 - DEBUG - response_closed.complete
2026-01-22 14:27:00,252 - google_genai.types - WARNING - Warning: there are non-text parts in the response: ['thought_signature'], returning concatenated parsed result from text parts. Check the full candidates.content.parts accessor to get the full model response.
2026-01-22 14:27:00,253 - google_genai.types - WARNING - Warning: there are non-text parts in the response: ['thought_signature'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.
2026-01-22 14:27:00,253 - question_generation - INFO - Successfully separated 5 questions and 5 answer key items.
2026-01-22 14:27:00,254 - file_utils - INFO - Cleaned up file: D:\Learning Analytics\Learning-AI\Question_and_Answer_Generation_with_Feeddack\uploads\13-queryexecution.pdf
2026-01-22 14:27:00,255 - pdf_generation - INFO - Creating PDF file: D:\Learning Analytics\Learning-AI\Question_and_Answer_Generation_with_Feeddack\results\generated_mcqs_13-queryexecution_questions.pdf
2026-01-22 14:27:00,262 - fpdf.output - DEBUG - Final size summary of the biggest document sections:
2026-01-22 14:27:00,262 - fpdf.output - DEBUG - - pages: 1.2KiB
2026-01-22 14:27:00,262 - fpdf.output - DEBUG - - fonts: 199.0B
2026-01-22 14:27:00,262 - pdf_generation - INFO - PDF successfully generated at D:\Learning Analytics\Learning-AI\Question_and_Answer_Generation_with_Feeddack\results\generated_mcqs_13-queryexecution_questions.pdf
2026-01-22 14:27:00,262 - file_utils - INFO - Saving TXT results for: 13-queryexecution.pdf
2026-01-22 14:27:00,263 - pdf_generation - INFO - Saving merged questions to text file: generated_mcqs_13-queryexecution_key.txt
2026-01-22 14:27:00,263 - pdf_generation - INFO - Successfully saved 5 questions to text file.
2026-01-22 14:27:00,263 - file_utils - INFO - TXT file saved: generated_mcqs_13-queryexecution_key.txt
2026-01-22 14:27:00,264 - routes - INFO - Successfully generated 5 questions.
2026-01-22 14:27:00,264 - httpcore.connection - DEBUG - close.started
2026-01-22 14:27:00,264 - httpcore.connection - DEBUG - close.complete
2026-01-22 14:27:00,266 - werkzeug - INFO - 127.0.0.1 - - [22/Jan/2026 14:27:00] "POST /generate HTTP/1.1" 200 -
2026-01-22 14:27:18,408 - question_generation - INFO - QuestionGenerator initialized with model: gemini-3-flash-preview
2026-01-22 14:27:18,408 - question_generation - INFO - Generating structured content using model gemini-3-flash-preview...
2026-01-22 14:27:18,409 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2026-01-22 14:27:18,409 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2026-01-22 14:27:18,429 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002BEC845AD50>
2026-01-22 14:27:18,429 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000002BEC9538C30> server_hostname='generativelanguage.googleapis.com' timeout=None
2026-01-22 14:27:18,449 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002BEC845B450>
2026-01-22 14:27:18,449 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2026-01-22 14:27:18,449 - httpcore.http11 - DEBUG - send_request_headers.complete
2026-01-22 14:27:18,449 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2026-01-22 14:27:18,449 - httpcore.http11 - DEBUG - send_request_body.complete
2026-01-22 14:27:18,449 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2026-01-22 14:27:25,157 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 22 Jan 2026 08:57:25 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=6690'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2026-01-22 14:27:25,158 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-3-flash-preview:generateContent "HTTP/1.1 200 OK"
2026-01-22 14:27:25,158 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2026-01-22 14:27:25,159 - httpcore.http11 - DEBUG - receive_response_body.complete
2026-01-22 14:27:25,159 - httpcore.http11 - DEBUG - response_closed.started
2026-01-22 14:27:25,159 - httpcore.http11 - DEBUG - response_closed.complete
2026-01-22 14:27:25,160 - google_genai.types - WARNING - Warning: there are non-text parts in the response: ['thought_signature'], returning concatenated parsed result from text parts. Check the full candidates.content.parts accessor to get the full model response.
2026-01-22 14:27:25,161 - google_genai.types - WARNING - Warning: there are non-text parts in the response: ['thought_signature'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.
2026-01-22 14:27:25,161 - pdf_generation - INFO - Creating PDF file: D:\Learning Analytics\Learning-AI\Question_and_Answer_Generation_with_Feeddack\results\generated_mcqs_13-queryexecution_questions.pdf
2026-01-22 14:27:25,168 - fpdf.output - DEBUG - Final size summary of the biggest document sections:
2026-01-22 14:27:25,168 - fpdf.output - DEBUG - - pages: 1.0KiB
2026-01-22 14:27:25,168 - fpdf.output - DEBUG - - fonts: 199.0B
2026-01-22 14:27:25,168 - pdf_generation - INFO - PDF successfully generated at D:\Learning Analytics\Learning-AI\Question_and_Answer_Generation_with_Feeddack\results\generated_mcqs_13-queryexecution_questions.pdf
2026-01-22 14:27:25,168 - file_utils - INFO - Saving TXT results for: 13-queryexecution.pdf
2026-01-22 14:27:25,169 - pdf_generation - INFO - Saving merged questions to text file: generated_mcqs_13-queryexecution_key.txt
2026-01-22 14:27:25,169 - pdf_generation - INFO - Successfully saved 4 questions to text file.
2026-01-22 14:27:25,169 - file_utils - INFO - TXT file saved: generated_mcqs_13-queryexecution_key.txt
2026-01-22 14:27:25,169 - httpcore.connection - DEBUG - close.started
2026-01-22 14:27:25,169 - httpcore.connection - DEBUG - close.complete
2026-01-22 14:27:25,171 - werkzeug - INFO - 127.0.0.1 - - [22/Jan/2026 14:27:25] "POST /reframe_question HTTP/1.1" 200 -
2026-01-22 14:27:25,177 - routes - INFO - Display Results Called
2026-01-22 14:27:25,180 - werkzeug - INFO - 127.0.0.1 - - [22/Jan/2026 14:27:25] "GET /display_results HTTP/1.1" 200 -
2026-01-22 14:27:57,161 - routes - INFO - Rendering home page
2026-01-22 14:27:57,162 - werkzeug - INFO - 127.0.0.1 - - [22/Jan/2026 14:27:57] "GET / HTTP/1.1" 200 -
2026-01-22 14:27:59,617 - routes - INFO - Rendering Question generator page
2026-01-22 14:27:59,618 - werkzeug - INFO - 127.0.0.1 - - [22/Jan/2026 14:27:59] "GET /mcq-generator HTTP/1.1" 200 -
2026-01-22 14:28:10,440 - routes - INFO - Received Question generation request
2026-01-22 14:28:10,445 - validation - INFO - File and parameters validated successfully.
2026-01-22 14:28:10,446 - file_utils - DEBUG - File 13-queryexecution.pdf allowed: True
2026-01-22 14:28:10,450 - file_utils - INFO - File saved to: D:\Learning Analytics\Learning-AI\Question_and_Answer_Generation_with_Feeddack\uploads\13-queryexecution.pdf
2026-01-22 14:28:10,529 - pdf_extraction_util - INFO - Successfully extracted 38407 characters from 13-queryexecution.pdf
2026-01-22 14:28:10,535 - routes - INFO - Successfully saved content for 13-queryexecution.pdf to Context table.
2026-01-22 14:28:10,996 - question_generation - INFO - QuestionGenerator initialized with model: gemini-3-flash-preview
2026-01-22 14:28:10,996 - question_generation - INFO - Generating structured content using model gemini-3-flash-preview...
2026-01-22 14:28:10,996 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2026-01-22 14:28:10,997 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2026-01-22 14:28:11,014 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002BEC95C7890>
2026-01-22 14:28:11,014 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000002BEC95AC190> server_hostname='generativelanguage.googleapis.com' timeout=None
2026-01-22 14:28:11,032 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002BEC95C7A70>
2026-01-22 14:28:11,033 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2026-01-22 14:28:11,033 - httpcore.http11 - DEBUG - send_request_headers.complete
2026-01-22 14:28:11,033 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2026-01-22 14:28:11,033 - httpcore.http11 - DEBUG - send_request_body.complete
2026-01-22 14:28:11,033 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2026-01-22 14:28:24,452 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 22 Jan 2026 08:58:24 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=13402'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2026-01-22 14:28:24,452 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-3-flash-preview:generateContent "HTTP/1.1 200 OK"
2026-01-22 14:28:24,452 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2026-01-22 14:28:24,454 - httpcore.http11 - DEBUG - receive_response_body.complete
2026-01-22 14:28:24,454 - httpcore.http11 - DEBUG - response_closed.started
2026-01-22 14:28:24,454 - httpcore.http11 - DEBUG - response_closed.complete
2026-01-22 14:28:24,455 - google_genai.types - WARNING - Warning: there are non-text parts in the response: ['thought_signature'], returning concatenated parsed result from text parts. Check the full candidates.content.parts accessor to get the full model response.
2026-01-22 14:28:24,455 - google_genai.types - WARNING - Warning: there are non-text parts in the response: ['thought_signature'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.
2026-01-22 14:28:24,455 - question_generation - INFO - Successfully separated 5 questions and 5 answer key items.
2026-01-22 14:28:24,455 - file_utils - INFO - Cleaned up file: D:\Learning Analytics\Learning-AI\Question_and_Answer_Generation_with_Feeddack\uploads\13-queryexecution.pdf
2026-01-22 14:28:24,456 - pdf_generation - INFO - Creating PDF file: D:\Learning Analytics\Learning-AI\Question_and_Answer_Generation_with_Feeddack\results\generated_mcqs_13-queryexecution_questions.pdf
2026-01-22 14:28:24,459 - fpdf.fpdf - DEBUG - Page break on page 1 at y=273 for element of height 6 > 277
2026-01-22 14:28:24,460 - fpdf.output - DEBUG - Final size summary of the biggest document sections:
2026-01-22 14:28:24,460 - fpdf.output - DEBUG - - pages: 1.8KiB
2026-01-22 14:28:24,460 - fpdf.output - DEBUG - - fonts: 199.0B
2026-01-22 14:28:24,460 - pdf_generation - INFO - PDF successfully generated at D:\Learning Analytics\Learning-AI\Question_and_Answer_Generation_with_Feeddack\results\generated_mcqs_13-queryexecution_questions.pdf
2026-01-22 14:28:24,461 - file_utils - INFO - Saving TXT results for: 13-queryexecution.pdf
2026-01-22 14:28:24,461 - pdf_generation - INFO - Saving merged questions to text file: generated_mcqs_13-queryexecution_key.txt
2026-01-22 14:28:24,461 - pdf_generation - INFO - Successfully saved 5 questions to text file.
2026-01-22 14:28:24,462 - file_utils - INFO - TXT file saved: generated_mcqs_13-queryexecution_key.txt
2026-01-22 14:28:24,462 - routes - INFO - Successfully generated 5 questions.
2026-01-22 14:28:24,462 - httpcore.connection - DEBUG - close.started
2026-01-22 14:28:24,462 - httpcore.connection - DEBUG - close.complete
2026-01-22 14:28:24,464 - werkzeug - INFO - 127.0.0.1 - - [22/Jan/2026 14:28:24] "POST /generate HTTP/1.1" 200 -
2026-01-22 14:28:37,952 - question_generation - INFO - QuestionGenerator initialized with model: gemini-3-flash-preview
2026-01-22 14:28:37,953 - question_generation - INFO - Generating structured content using model gemini-3-flash-preview...
2026-01-22 14:28:37,953 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2026-01-22 14:28:37,954 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2026-01-22 14:28:37,971 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002BEC95B9E10>
2026-01-22 14:28:37,971 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000002BEC95ACB90> server_hostname='generativelanguage.googleapis.com' timeout=None
2026-01-22 14:28:37,990 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002BEC95BA190>
2026-01-22 14:28:37,990 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2026-01-22 14:28:37,991 - httpcore.http11 - DEBUG - send_request_headers.complete
2026-01-22 14:28:37,991 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2026-01-22 14:28:37,991 - httpcore.http11 - DEBUG - send_request_body.complete
2026-01-22 14:28:37,991 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2026-01-22 14:28:44,453 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 22 Jan 2026 08:58:44 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=6440'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2026-01-22 14:28:44,454 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-3-flash-preview:generateContent "HTTP/1.1 200 OK"
2026-01-22 14:28:44,454 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2026-01-22 14:28:44,455 - httpcore.http11 - DEBUG - receive_response_body.complete
2026-01-22 14:28:44,455 - httpcore.http11 - DEBUG - response_closed.started
2026-01-22 14:28:44,456 - httpcore.http11 - DEBUG - response_closed.complete
2026-01-22 14:28:44,457 - google_genai.types - WARNING - Warning: there are non-text parts in the response: ['thought_signature'], returning concatenated parsed result from text parts. Check the full candidates.content.parts accessor to get the full model response.
2026-01-22 14:28:44,457 - google_genai.types - WARNING - Warning: there are non-text parts in the response: ['thought_signature'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.
2026-01-22 14:28:44,457 - pdf_generation - INFO - Creating PDF file: D:\Learning Analytics\Learning-AI\Question_and_Answer_Generation_with_Feeddack\results\generated_mcqs_13-queryexecution_questions.pdf
2026-01-22 14:28:44,466 - fpdf.output - DEBUG - Final size summary of the biggest document sections:
2026-01-22 14:28:44,466 - fpdf.output - DEBUG - - pages: 1.3KiB
2026-01-22 14:28:44,466 - fpdf.output - DEBUG - - fonts: 199.0B
2026-01-22 14:28:44,466 - pdf_generation - INFO - PDF successfully generated at D:\Learning Analytics\Learning-AI\Question_and_Answer_Generation_with_Feeddack\results\generated_mcqs_13-queryexecution_questions.pdf
2026-01-22 14:28:44,467 - file_utils - INFO - Saving TXT results for: 13-queryexecution.pdf
2026-01-22 14:28:44,467 - pdf_generation - INFO - Saving merged questions to text file: generated_mcqs_13-queryexecution_key.txt
2026-01-22 14:28:44,468 - pdf_generation - INFO - Successfully saved 4 questions to text file.
2026-01-22 14:28:44,468 - file_utils - INFO - TXT file saved: generated_mcqs_13-queryexecution_key.txt
2026-01-22 14:28:44,468 - httpcore.connection - DEBUG - close.started
2026-01-22 14:28:44,468 - httpcore.connection - DEBUG - close.complete
2026-01-22 14:28:44,471 - werkzeug - INFO - 127.0.0.1 - - [22/Jan/2026 14:28:44] "POST /reframe_question HTTP/1.1" 200 -
2026-01-22 14:28:44,477 - routes - INFO - Display Results Called
2026-01-22 14:28:44,480 - werkzeug - INFO - 127.0.0.1 - - [22/Jan/2026 14:28:44] "GET /display_results HTTP/1.1" 200 -
2026-01-22 14:29:17,471 - routes - INFO - Rendering home page
2026-01-22 14:29:17,472 - werkzeug - INFO - 127.0.0.1 - - [22/Jan/2026 14:29:17] "GET / HTTP/1.1" 200 -
2026-01-22 14:29:20,318 - routes - INFO - Rendering Question generator page
2026-01-22 14:29:20,319 - werkzeug - INFO - 127.0.0.1 - - [22/Jan/2026 14:29:20] "GET /mcq-generator HTTP/1.1" 200 -
2026-01-22 14:29:32,651 - routes - INFO - Received Question generation request
2026-01-22 14:29:32,656 - validation - INFO - File and parameters validated successfully.
2026-01-22 14:29:32,656 - file_utils - DEBUG - File 13-queryexecution.pdf allowed: True
2026-01-22 14:29:32,659 - file_utils - INFO - File saved to: D:\Learning Analytics\Learning-AI\Question_and_Answer_Generation_with_Feeddack\uploads\13-queryexecution.pdf
2026-01-22 14:29:32,737 - pdf_extraction_util - INFO - Successfully extracted 38407 characters from 13-queryexecution.pdf
2026-01-22 14:29:32,742 - routes - INFO - Successfully saved content for 13-queryexecution.pdf to Context table.
2026-01-22 14:29:33,198 - question_generation - INFO - QuestionGenerator initialized with model: gemini-3-flash-preview
2026-01-22 14:29:33,198 - question_generation - INFO - Generating structured content using model gemini-3-flash-preview...
2026-01-22 14:29:33,198 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2026-01-22 14:29:33,199 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2026-01-22 14:29:33,216 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002BEC846BEE0>
2026-01-22 14:29:33,216 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000002BEC9538EB0> server_hostname='generativelanguage.googleapis.com' timeout=None
2026-01-22 14:29:33,236 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002BEC82F7050>
2026-01-22 14:29:33,236 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2026-01-22 14:29:33,237 - httpcore.http11 - DEBUG - send_request_headers.complete
2026-01-22 14:29:33,237 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2026-01-22 14:29:33,237 - httpcore.http11 - DEBUG - send_request_body.complete
2026-01-22 14:29:33,237 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2026-01-22 14:29:49,512 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 22 Jan 2026 08:59:49 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=16256'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2026-01-22 14:29:49,512 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-3-flash-preview:generateContent "HTTP/1.1 200 OK"
2026-01-22 14:29:49,512 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2026-01-22 14:29:49,512 - httpcore.http11 - DEBUG - receive_response_body.complete
2026-01-22 14:29:49,513 - httpcore.http11 - DEBUG - response_closed.started
2026-01-22 14:29:49,513 - httpcore.http11 - DEBUG - response_closed.complete
2026-01-22 14:29:49,513 - google_genai.types - WARNING - Warning: there are non-text parts in the response: ['thought_signature'], returning concatenated parsed result from text parts. Check the full candidates.content.parts accessor to get the full model response.
2026-01-22 14:29:49,513 - google_genai.types - WARNING - Warning: there are non-text parts in the response: ['thought_signature'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.
2026-01-22 14:29:49,513 - question_generation - INFO - Successfully separated 5 questions and 5 answer key items.
2026-01-22 14:29:49,514 - file_utils - INFO - Cleaned up file: D:\Learning Analytics\Learning-AI\Question_and_Answer_Generation_with_Feeddack\uploads\13-queryexecution.pdf
2026-01-22 14:29:49,514 - pdf_generation - INFO - Creating PDF file: D:\Learning Analytics\Learning-AI\Question_and_Answer_Generation_with_Feeddack\results\generated_mcqs_13-queryexecution_questions.pdf
2026-01-22 14:29:49,519 - fpdf.fpdf - DEBUG - Page break on page 1 at y=277 for element of height 6 > 277
2026-01-22 14:29:49,522 - fpdf.output - DEBUG - Final size summary of the biggest document sections:
2026-01-22 14:29:49,522 - fpdf.output - DEBUG - - pages: 3.6KiB
2026-01-22 14:29:49,522 - fpdf.output - DEBUG - - fonts: 199.0B
2026-01-22 14:29:49,523 - pdf_generation - INFO - PDF successfully generated at D:\Learning Analytics\Learning-AI\Question_and_Answer_Generation_with_Feeddack\results\generated_mcqs_13-queryexecution_questions.pdf
2026-01-22 14:29:49,524 - file_utils - INFO - Saving TXT results for: 13-queryexecution.pdf
2026-01-22 14:29:49,525 - pdf_generation - INFO - Saving merged questions to text file: generated_mcqs_13-queryexecution_key.txt
2026-01-22 14:29:49,527 - pdf_generation - INFO - Successfully saved 5 questions to text file.
2026-01-22 14:29:49,527 - file_utils - INFO - TXT file saved: generated_mcqs_13-queryexecution_key.txt
2026-01-22 14:29:49,527 - routes - INFO - Successfully generated 5 questions.
2026-01-22 14:29:49,528 - httpcore.connection - DEBUG - close.started
2026-01-22 14:29:49,528 - httpcore.connection - DEBUG - close.complete
2026-01-22 14:29:49,530 - werkzeug - INFO - 127.0.0.1 - - [22/Jan/2026 14:29:49] "POST /generate HTTP/1.1" 200 -
2026-01-22 14:30:02,307 - question_generation - INFO - QuestionGenerator initialized with model: gemini-3-flash-preview
2026-01-22 14:30:02,307 - question_generation - INFO - Generating structured content using model gemini-3-flash-preview...
2026-01-22 14:30:02,308 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2026-01-22 14:30:02,308 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2026-01-22 14:30:02,325 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002BEC82F6F90>
2026-01-22 14:30:02,325 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000002BEC9539270> server_hostname='generativelanguage.googleapis.com' timeout=None
2026-01-22 14:30:02,351 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002BEC82DB540>
2026-01-22 14:30:02,351 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2026-01-22 14:30:02,352 - httpcore.http11 - DEBUG - send_request_headers.complete
2026-01-22 14:30:02,352 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2026-01-22 14:30:02,352 - httpcore.http11 - DEBUG - send_request_body.complete
2026-01-22 14:30:02,352 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2026-01-22 14:30:10,739 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 22 Jan 2026 09:00:10 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=8369'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2026-01-22 14:30:10,740 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-3-flash-preview:generateContent "HTTP/1.1 200 OK"
2026-01-22 14:30:10,740 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2026-01-22 14:30:10,743 - httpcore.http11 - DEBUG - receive_response_body.complete
2026-01-22 14:30:10,743 - httpcore.http11 - DEBUG - response_closed.started
2026-01-22 14:30:10,743 - httpcore.http11 - DEBUG - response_closed.complete
2026-01-22 14:30:10,744 - google_genai.types - WARNING - Warning: there are non-text parts in the response: ['thought_signature'], returning concatenated parsed result from text parts. Check the full candidates.content.parts accessor to get the full model response.
2026-01-22 14:30:10,745 - google_genai.types - WARNING - Warning: there are non-text parts in the response: ['thought_signature'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.
2026-01-22 14:30:10,745 - pdf_generation - INFO - Creating PDF file: D:\Learning Analytics\Learning-AI\Question_and_Answer_Generation_with_Feeddack\results\generated_mcqs_13-queryexecution_questions.pdf
2026-01-22 14:30:10,757 - fpdf.fpdf - DEBUG - Page break on page 1 at y=277 for element of height 6 > 277
2026-01-22 14:30:10,759 - fpdf.output - DEBUG - Final size summary of the biggest document sections:
2026-01-22 14:30:10,759 - fpdf.output - DEBUG - - pages: 2.9KiB
2026-01-22 14:30:10,759 - fpdf.output - DEBUG - - fonts: 199.0B
2026-01-22 14:30:10,760 - pdf_generation - INFO - PDF successfully generated at D:\Learning Analytics\Learning-AI\Question_and_Answer_Generation_with_Feeddack\results\generated_mcqs_13-queryexecution_questions.pdf
2026-01-22 14:30:10,760 - file_utils - INFO - Saving TXT results for: 13-queryexecution.pdf
2026-01-22 14:30:10,760 - pdf_generation - INFO - Saving merged questions to text file: generated_mcqs_13-queryexecution_key.txt
2026-01-22 14:30:10,761 - pdf_generation - INFO - Successfully saved 4 questions to text file.
2026-01-22 14:30:10,761 - file_utils - INFO - TXT file saved: generated_mcqs_13-queryexecution_key.txt
2026-01-22 14:30:10,761 - httpcore.connection - DEBUG - close.started
2026-01-22 14:30:10,761 - httpcore.connection - DEBUG - close.complete
2026-01-22 14:30:10,763 - werkzeug - INFO - 127.0.0.1 - - [22/Jan/2026 14:30:10] "POST /reframe_question HTTP/1.1" 200 -
2026-01-22 14:30:10,769 - routes - INFO - Display Results Called
2026-01-22 14:30:10,770 - werkzeug - INFO - 127.0.0.1 - - [22/Jan/2026 14:30:10] "GET /display_results HTTP/1.1" 200 -
2026-01-22 14:31:01,725 - routes - INFO - Rendering home page
2026-01-22 14:31:01,725 - werkzeug - INFO - 127.0.0.1 - - [22/Jan/2026 14:31:01] "GET / HTTP/1.1" 200 -
2026-01-22 14:31:04,044 - routes - INFO - Rendering Question generator page
2026-01-22 14:31:04,045 - werkzeug - INFO - 127.0.0.1 - - [22/Jan/2026 14:31:04] "GET /mcq-generator HTTP/1.1" 200 -
2026-01-22 14:31:10,698 - routes - INFO - Received Question generation request
2026-01-22 14:31:10,705 - validation - INFO - File and parameters validated successfully.
2026-01-22 14:31:10,705 - file_utils - DEBUG - File 13-queryexecution.pdf allowed: True
2026-01-22 14:31:10,708 - file_utils - INFO - File saved to: D:\Learning Analytics\Learning-AI\Question_and_Answer_Generation_with_Feeddack\uploads\13-queryexecution.pdf
2026-01-22 14:31:10,787 - pdf_extraction_util - INFO - Successfully extracted 38407 characters from 13-queryexecution.pdf
2026-01-22 14:31:10,791 - routes - INFO - Successfully saved content for 13-queryexecution.pdf to Context table.
2026-01-22 14:31:11,244 - question_generation - INFO - QuestionGenerator initialized with model: gemini-3-flash-preview
2026-01-22 14:31:11,245 - question_generation - INFO - Generating structured content using model gemini-3-flash-preview...
2026-01-22 14:31:11,245 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2026-01-22 14:31:11,246 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2026-01-22 14:31:11,267 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002BEC82D9FF0>
2026-01-22 14:31:11,267 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000002BEC95382D0> server_hostname='generativelanguage.googleapis.com' timeout=None
2026-01-22 14:31:11,290 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002BEC953A0D0>
2026-01-22 14:31:11,291 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2026-01-22 14:31:11,291 - httpcore.http11 - DEBUG - send_request_headers.complete
2026-01-22 14:31:11,291 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2026-01-22 14:31:11,291 - httpcore.http11 - DEBUG - send_request_body.complete
2026-01-22 14:31:11,291 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2026-01-22 14:31:27,913 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 22 Jan 2026 09:01:27 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=16602'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2026-01-22 14:31:27,914 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-3-flash-preview:generateContent "HTTP/1.1 200 OK"
2026-01-22 14:31:27,914 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2026-01-22 14:31:27,915 - httpcore.http11 - DEBUG - receive_response_body.complete
2026-01-22 14:31:27,915 - httpcore.http11 - DEBUG - response_closed.started
2026-01-22 14:31:27,915 - httpcore.http11 - DEBUG - response_closed.complete
2026-01-22 14:31:27,917 - google_genai.types - WARNING - Warning: there are non-text parts in the response: ['thought_signature'], returning concatenated parsed result from text parts. Check the full candidates.content.parts accessor to get the full model response.
2026-01-22 14:31:27,917 - google_genai.types - WARNING - Warning: there are non-text parts in the response: ['thought_signature'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.
2026-01-22 14:31:27,917 - question_generation - INFO - Successfully separated 5 questions and 5 answer key items.
2026-01-22 14:31:27,919 - file_utils - INFO - Cleaned up file: D:\Learning Analytics\Learning-AI\Question_and_Answer_Generation_with_Feeddack\uploads\13-queryexecution.pdf
2026-01-22 14:31:27,919 - pdf_generation - INFO - Creating PDF file: D:\Learning Analytics\Learning-AI\Question_and_Answer_Generation_with_Feeddack\results\generated_mcqs_13-queryexecution_questions.pdf
2026-01-22 14:31:27,927 - fpdf.fpdf - DEBUG - Page break on page 1 at y=283 for element of height 6 > 277
2026-01-22 14:31:27,930 - fpdf.output - DEBUG - Final size summary of the biggest document sections:
2026-01-22 14:31:27,930 - fpdf.output - DEBUG - - pages: 2.6KiB
2026-01-22 14:31:27,930 - fpdf.output - DEBUG - - fonts: 304.0B
2026-01-22 14:31:27,930 - pdf_generation - INFO - PDF successfully generated at D:\Learning Analytics\Learning-AI\Question_and_Answer_Generation_with_Feeddack\results\generated_mcqs_13-queryexecution_questions.pdf
2026-01-22 14:31:27,930 - file_utils - INFO - Saving TXT results for: 13-queryexecution.pdf
2026-01-22 14:31:27,931 - pdf_generation - INFO - Saving merged questions to text file: generated_mcqs_13-queryexecution_key.txt
2026-01-22 14:31:27,931 - pdf_generation - INFO - Successfully saved 5 questions to text file.
2026-01-22 14:31:27,931 - file_utils - INFO - TXT file saved: generated_mcqs_13-queryexecution_key.txt
2026-01-22 14:31:27,931 - routes - INFO - Successfully generated 5 questions.
2026-01-22 14:31:27,931 - httpcore.connection - DEBUG - close.started
2026-01-22 14:31:27,932 - httpcore.connection - DEBUG - close.complete
2026-01-22 14:31:27,933 - werkzeug - INFO - 127.0.0.1 - - [22/Jan/2026 14:31:27] "POST /generate HTTP/1.1" 200 -
2026-01-22 14:31:36,123 - question_generation - INFO - QuestionGenerator initialized with model: gemini-3-flash-preview
2026-01-22 14:31:36,123 - question_generation - INFO - Generating structured content using model gemini-3-flash-preview...
2026-01-22 14:31:36,123 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2026-01-22 14:31:36,124 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2026-01-22 14:31:36,144 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002BEC953AF30>
2026-01-22 14:31:36,144 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000002BEC9539BD0> server_hostname='generativelanguage.googleapis.com' timeout=None
2026-01-22 14:31:36,163 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002BEC95FA4E0>
2026-01-22 14:31:36,163 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2026-01-22 14:31:36,163 - httpcore.http11 - DEBUG - send_request_headers.complete
2026-01-22 14:31:36,163 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2026-01-22 14:31:36,163 - httpcore.http11 - DEBUG - send_request_body.complete
2026-01-22 14:31:36,163 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2026-01-22 14:31:52,978 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 22 Jan 2026 09:01:52 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=16794'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2026-01-22 14:31:52,978 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-3-flash-preview:generateContent "HTTP/1.1 200 OK"
2026-01-22 14:31:52,979 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2026-01-22 14:31:52,981 - httpcore.http11 - DEBUG - receive_response_body.complete
2026-01-22 14:31:52,981 - httpcore.http11 - DEBUG - response_closed.started
2026-01-22 14:31:52,981 - httpcore.http11 - DEBUG - response_closed.complete
2026-01-22 14:31:52,982 - google_genai.types - WARNING - Warning: there are non-text parts in the response: ['thought_signature'], returning concatenated parsed result from text parts. Check the full candidates.content.parts accessor to get the full model response.
2026-01-22 14:31:52,983 - google_genai.types - WARNING - Warning: there are non-text parts in the response: ['thought_signature'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.
2026-01-22 14:31:52,983 - pdf_generation - INFO - Creating PDF file: D:\Learning Analytics\Learning-AI\Question_and_Answer_Generation_with_Feeddack\results\generated_mcqs_13-queryexecution_questions.pdf
2026-01-22 14:31:52,992 - fpdf.fpdf - DEBUG - Page break on page 1 at y=277 for element of height 6 > 277
2026-01-22 14:31:52,994 - fpdf.output - DEBUG - Final size summary of the biggest document sections:
2026-01-22 14:31:52,994 - fpdf.output - DEBUG - - pages: 2.1KiB
2026-01-22 14:31:52,994 - fpdf.output - DEBUG - - fonts: 304.0B
2026-01-22 14:31:52,995 - pdf_generation - INFO - PDF successfully generated at D:\Learning Analytics\Learning-AI\Question_and_Answer_Generation_with_Feeddack\results\generated_mcqs_13-queryexecution_questions.pdf
2026-01-22 14:31:52,995 - file_utils - INFO - Saving TXT results for: 13-queryexecution.pdf
2026-01-22 14:31:52,996 - pdf_generation - INFO - Saving merged questions to text file: generated_mcqs_13-queryexecution_key.txt
2026-01-22 14:31:52,996 - pdf_generation - INFO - Successfully saved 4 questions to text file.
2026-01-22 14:31:52,996 - file_utils - INFO - TXT file saved: generated_mcqs_13-queryexecution_key.txt
2026-01-22 14:31:52,997 - httpcore.connection - DEBUG - close.started
2026-01-22 14:31:52,997 - httpcore.connection - DEBUG - close.complete
2026-01-22 14:31:52,998 - werkzeug - INFO - 127.0.0.1 - - [22/Jan/2026 14:31:52] "POST /reframe_question HTTP/1.1" 200 -
2026-01-22 14:31:53,004 - routes - INFO - Display Results Called
2026-01-22 14:31:53,006 - werkzeug - INFO - 127.0.0.1 - - [22/Jan/2026 14:31:53] "GET /display_results HTTP/1.1" 200 -
2026-01-22 14:36:29,953 - werkzeug - INFO -  * Detected change in 'D:\\Learning Analytics\\Learning-AI\\Question_and_Answer_Generation_with_Feeddack\\app\\routes.py', reloading
2026-01-22 14:36:29,954 - ragas._analytics - DEBUG - AnalyticsBatcher shutdown complete
