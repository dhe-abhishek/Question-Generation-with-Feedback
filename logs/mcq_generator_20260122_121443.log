2026-01-22 12:14:44,189 - matplotlib - DEBUG - matplotlib data path: D:\Learning Analytics\Learning-AI\Learning_Analytics-API\venv\Lib\site-packages\matplotlib\mpl-data
2026-01-22 12:14:44,199 - matplotlib - DEBUG - CONFIGDIR=C:\Users\Administrator\.matplotlib
2026-01-22 12:14:44,200 - matplotlib - DEBUG - interactive is False
2026-01-22 12:14:44,200 - matplotlib - DEBUG - platform is win32
2026-01-22 12:14:44,249 - matplotlib - DEBUG - CACHEDIR=C:\Users\Administrator\.matplotlib
2026-01-22 12:14:44,251 - matplotlib.font_manager - DEBUG - Using fontManager instance from C:\Users\Administrator\.matplotlib\fontlist-v390.json
2026-01-22 12:14:46,876 - datasets - DEBUG - PyTorch version 2.9.0 available.
2026-01-22 12:14:50,397 - ragas._analytics - DEBUG - Starting AnalyticsBatcher thread with interval 10 seconds
2026-01-22 12:14:51,430 - relevancy_utils - INFO - Starting Ragas scorer initialization...
2026-01-22 12:14:52,003 - relevancy_utils - DEBUG - ChatGroq LLM initialized.
2026-01-22 12:14:53,477 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cpu
2026-01-22 12:14:53,477 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2026-01-22 12:14:53,481 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): huggingface.co:443
2026-01-22 12:14:54,007 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/modules.json HTTP/1.1" 307 0
2026-01-22 12:14:54,026 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/modules.json HTTP/1.1" 200 0
2026-01-22 12:14:54,260 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/config_sentence_transformers.json HTTP/1.1" 307 0
2026-01-22 12:14:54,279 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config_sentence_transformers.json HTTP/1.1" 200 0
2026-01-22 12:14:54,502 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/config_sentence_transformers.json HTTP/1.1" 307 0
2026-01-22 12:14:54,521 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config_sentence_transformers.json HTTP/1.1" 200 0
2026-01-22 12:14:54,741 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/README.md HTTP/1.1" 307 0
2026-01-22 12:14:54,758 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/README.md HTTP/1.1" 200 0
2026-01-22 12:14:54,978 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/modules.json HTTP/1.1" 307 0
2026-01-22 12:14:54,997 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/modules.json HTTP/1.1" 200 0
2026-01-22 12:14:55,218 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/sentence_bert_config.json HTTP/1.1" 307 0
2026-01-22 12:14:55,237 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/sentence_bert_config.json HTTP/1.1" 200 0
2026-01-22 12:14:55,459 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/adapter_config.json HTTP/1.1" 404 0
2026-01-22 12:14:55,684 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 307 0
2026-01-22 12:14:55,703 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config.json HTTP/1.1" 200 0
2026-01-22 12:14:56,013 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2026-01-22 12:14:56,031 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/tokenizer_config.json HTTP/1.1" 200 0
2026-01-22 12:14:56,267 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "GET /api/models/sentence-transformers/all-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2026-01-22 12:14:56,523 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/1_Pooling/config.json HTTP/1.1" 307 0
2026-01-22 12:14:56,542 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/1_Pooling%2Fconfig.json HTTP/1.1" 200 0
2026-01-22 12:14:56,771 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "GET /api/models/sentence-transformers/all-MiniLM-L6-v2 HTTP/1.1" 200 6831
2026-01-22 12:14:56,777 - relevancy_utils - DEBUG - HuggingFace Embeddings initialized.
2026-01-22 12:14:56,777 - relevancy_utils - INFO - Ragas ResponseRelevancy scorer initialized successfully.
2026-01-22 12:14:56,779 - faithfulness_utils - INFO - Initializing Faithfulness scorer...
2026-01-22 12:14:57,311 - faithfulness_utils - INFO - Faithfulness scorer initialized successfully.
2026-01-22 12:14:57,325 - werkzeug - WARNING -  * Debugger is active!
2026-01-22 12:14:57,328 - werkzeug - INFO -  * Debugger PIN: 103-783-783
2026-01-22 12:14:57,652 - routes - INFO - Rendering home page
2026-01-22 12:14:57,667 - werkzeug - INFO - 127.0.0.1 - - [22/Jan/2026 12:14:57] "GET / HTTP/1.1" 200 -
2026-01-22 12:20:23,375 - routes - INFO - Rendering Question generator page
2026-01-22 12:20:23,383 - werkzeug - INFO - 127.0.0.1 - - [22/Jan/2026 12:20:23] "GET /mcq-generator HTTP/1.1" 200 -
2026-01-22 12:20:31,504 - routes - INFO - Received Question generation request
2026-01-22 12:20:31,514 - validation - INFO - File and parameters validated successfully.
2026-01-22 12:20:31,515 - file_utils - DEBUG - File 13-queryexecution.pdf allowed: True
2026-01-22 12:20:31,521 - file_utils - INFO - File saved to: D:\Learning Analytics\Learning-AI\Question_and_Answer_Generation_with_Feeddack\uploads\13-queryexecution.pdf
2026-01-22 12:20:31,667 - pdf_extraction_util - INFO - Successfully extracted 38407 characters from 13-queryexecution.pdf
2026-01-22 12:20:31,727 - routes - INFO - Successfully saved content for 13-queryexecution.pdf to Context table.
2026-01-22 12:20:32,618 - question_generation - INFO - QuestionGenerator initialized with model: gemini-3-flash-preview
2026-01-22 12:20:32,619 - question_generation - INFO - Generating structured content using model gemini-3-flash-preview...
2026-01-22 12:20:32,619 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2026-01-22 12:20:32,622 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2026-01-22 12:20:32,653 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001E5461DF770>
2026-01-22 12:20:32,654 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001E5461C47D0> server_hostname='generativelanguage.googleapis.com' timeout=None
2026-01-22 12:20:32,677 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001E546215BD0>
2026-01-22 12:20:32,677 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2026-01-22 12:20:32,678 - httpcore.http11 - DEBUG - send_request_headers.complete
2026-01-22 12:20:32,678 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2026-01-22 12:20:32,678 - httpcore.http11 - DEBUG - send_request_body.complete
2026-01-22 12:20:32,678 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2026-01-22 12:20:33,094 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Type', b'application/json; charset=UTF-8'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 22 Jan 2026 06:50:33 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=399'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2026-01-22 12:20:33,094 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-3-flash-preview:generateContent "HTTP/1.1 429 Too Many Requests"
2026-01-22 12:20:33,094 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2026-01-22 12:20:33,095 - httpcore.http11 - DEBUG - receive_response_body.complete
2026-01-22 12:20:33,095 - httpcore.http11 - DEBUG - response_closed.started
2026-01-22 12:20:33,095 - httpcore.http11 - DEBUG - response_closed.complete
2026-01-22 12:20:33,096 - question_generation - ERROR - Gemini API Error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-3-flash\nPlease retry in 26.81608833s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-3-flash', 'location': 'global'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '26s'}]}}
Traceback (most recent call last):
  File "D:\Learning Analytics\Learning-AI\Question_and_Answer_Generation_with_Feeddack\app\services\question_generation.py", line 270, in _generate_structured_content
    response = self.client.models.generate_content(
        model=self.model_name,
        contents=[prompt],
        config=generation_config
    )
  File "D:\Learning Analytics\Learning-AI\Learning_Analytics-API\venv\Lib\site-packages\google\genai\models.py", line 4983, in generate_content
    response = self._generate_content(
        model=model, contents=contents, config=parsed_config
    )
  File "D:\Learning Analytics\Learning-AI\Learning_Analytics-API\venv\Lib\site-packages\google\genai\models.py", line 3795, in _generate_content
    response = self._api_client.request(
        'post', path, request_dict, http_options
    )
  File "D:\Learning Analytics\Learning-AI\Learning_Analytics-API\venv\Lib\site-packages\google\genai\_api_client.py", line 1292, in request
    response = self._request(http_request, http_options, stream=False)
  File "D:\Learning Analytics\Learning-AI\Learning_Analytics-API\venv\Lib\site-packages\google\genai\_api_client.py", line 1128, in _request
    return self._retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
           ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Learning Analytics\Learning-AI\Learning_Analytics-API\venv\Lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
  File "D:\Learning Analytics\Learning-AI\Learning_Analytics-API\venv\Lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
  File "D:\Learning Analytics\Learning-AI\Learning_Analytics-API\venv\Lib\site-packages\tenacity\__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
          ~~~~~~~~~~~~~~~~~^^
  File "D:\Learning Analytics\Learning-AI\Learning_Analytics-API\venv\Lib\site-packages\tenacity\__init__.py", line 187, in reraise
    raise self.last_attempt.result()
          ~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python313\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ~~~~~~~~~~~~~~~~~^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python313\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "D:\Learning Analytics\Learning-AI\Learning_Analytics-API\venv\Lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
  File "D:\Learning Analytics\Learning-AI\Learning_Analytics-API\venv\Lib\site-packages\google\genai\_api_client.py", line 1105, in _request_once
    errors.APIError.raise_for_response(response)
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^
  File "D:\Learning Analytics\Learning-AI\Learning_Analytics-API\venv\Lib\site-packages\google\genai\errors.py", line 108, in raise_for_response
    raise ClientError(status_code, response_json, response)
google.genai.errors.ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-3-flash\nPlease retry in 26.81608833s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-3-flash', 'location': 'global'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '26s'}]}}
2026-01-22 12:20:33,117 - file_utils - INFO - Cleaned up file: D:\Learning Analytics\Learning-AI\Question_and_Answer_Generation_with_Feeddack\uploads\13-queryexecution.pdf
2026-01-22 12:20:33,119 - routes - ERROR - Question generation failed: Gemini API Error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-3-flash\nPlease retry in 26.81608833s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-3-flash', 'location': 'global'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '26s'}]}}
2026-01-22 12:20:33,128 - werkzeug - INFO - 127.0.0.1 - - [22/Jan/2026 12:20:33] "[32mPOST /generate HTTP/1.1[0m" 302 -
2026-01-22 12:20:33,134 - routes - INFO - Rendering Question generator page
2026-01-22 12:20:33,138 - httpcore.connection - DEBUG - close.started
2026-01-22 12:20:33,141 - httpcore.connection - DEBUG - close.complete
2026-01-22 12:20:33,145 - werkzeug - INFO - 127.0.0.1 - - [22/Jan/2026 12:20:33] "GET /mcq-generator HTTP/1.1" 200 -
2026-01-22 12:35:10,899 - routes - INFO - Rendering home page
2026-01-22 12:35:10,900 - werkzeug - INFO - 127.0.0.1 - - [22/Jan/2026 12:35:10] "GET / HTTP/1.1" 200 -
2026-01-22 12:35:15,317 - routes - INFO - Rendering Question generator page
2026-01-22 12:35:15,317 - werkzeug - INFO - 127.0.0.1 - - [22/Jan/2026 12:35:15] "GET /mcq-generator HTTP/1.1" 200 -
2026-01-22 12:35:21,755 - routes - INFO - Received Question generation request
2026-01-22 12:35:21,769 - validation - INFO - File and parameters validated successfully.
2026-01-22 12:35:21,770 - file_utils - DEBUG - File 13-queryexecution.pdf allowed: True
2026-01-22 12:35:21,778 - file_utils - INFO - File saved to: D:\Learning Analytics\Learning-AI\Question_and_Answer_Generation_with_Feeddack\uploads\13-queryexecution.pdf
2026-01-22 12:35:21,915 - pdf_extraction_util - INFO - Successfully extracted 38407 characters from 13-queryexecution.pdf
2026-01-22 12:35:21,923 - routes - INFO - Successfully saved content for 13-queryexecution.pdf to Context table.
2026-01-22 12:35:22,816 - question_generation - INFO - QuestionGenerator initialized with model: gemini-3-flash-preview
2026-01-22 12:35:22,817 - question_generation - INFO - Generating structured content using model gemini-3-flash-preview...
2026-01-22 12:35:22,817 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2026-01-22 12:35:22,819 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2026-01-22 12:35:22,850 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001E54610C910>
2026-01-22 12:35:22,850 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001E5461C4910> server_hostname='generativelanguage.googleapis.com' timeout=None
2026-01-22 12:35:22,871 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001E546237BB0>
2026-01-22 12:35:22,872 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2026-01-22 12:35:22,872 - httpcore.http11 - DEBUG - send_request_headers.complete
2026-01-22 12:35:22,872 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2026-01-22 12:35:22,873 - httpcore.http11 - DEBUG - send_request_body.complete
2026-01-22 12:35:22,873 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2026-01-22 12:35:23,305 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Type', b'application/json; charset=UTF-8'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 22 Jan 2026 07:05:23 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=404'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2026-01-22 12:35:23,306 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-3-flash-preview:generateContent "HTTP/1.1 429 Too Many Requests"
2026-01-22 12:35:23,307 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2026-01-22 12:35:23,308 - httpcore.http11 - DEBUG - receive_response_body.complete
2026-01-22 12:35:23,308 - httpcore.http11 - DEBUG - response_closed.started
2026-01-22 12:35:23,308 - httpcore.http11 - DEBUG - response_closed.complete
2026-01-22 12:35:23,309 - question_generation - ERROR - Gemini API Error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-3-flash\nPlease retry in 36.626274931s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-3-flash', 'location': 'global'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '36s'}]}}
Traceback (most recent call last):
  File "D:\Learning Analytics\Learning-AI\Question_and_Answer_Generation_with_Feeddack\app\services\question_generation.py", line 270, in _generate_structured_content
    response = self.client.models.generate_content(
        model=self.model_name,
        contents=[prompt],
        config=generation_config
    )
  File "D:\Learning Analytics\Learning-AI\Learning_Analytics-API\venv\Lib\site-packages\google\genai\models.py", line 4983, in generate_content
    response = self._generate_content(
        model=model, contents=contents, config=parsed_config
    )
  File "D:\Learning Analytics\Learning-AI\Learning_Analytics-API\venv\Lib\site-packages\google\genai\models.py", line 3795, in _generate_content
    response = self._api_client.request(
        'post', path, request_dict, http_options
    )
  File "D:\Learning Analytics\Learning-AI\Learning_Analytics-API\venv\Lib\site-packages\google\genai\_api_client.py", line 1292, in request
    response = self._request(http_request, http_options, stream=False)
  File "D:\Learning Analytics\Learning-AI\Learning_Analytics-API\venv\Lib\site-packages\google\genai\_api_client.py", line 1128, in _request
    return self._retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
           ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Learning Analytics\Learning-AI\Learning_Analytics-API\venv\Lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
  File "D:\Learning Analytics\Learning-AI\Learning_Analytics-API\venv\Lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
  File "D:\Learning Analytics\Learning-AI\Learning_Analytics-API\venv\Lib\site-packages\tenacity\__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
          ~~~~~~~~~~~~~~~~~^^
  File "D:\Learning Analytics\Learning-AI\Learning_Analytics-API\venv\Lib\site-packages\tenacity\__init__.py", line 187, in reraise
    raise self.last_attempt.result()
          ~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python313\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ~~~~~~~~~~~~~~~~~^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python313\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "D:\Learning Analytics\Learning-AI\Learning_Analytics-API\venv\Lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
  File "D:\Learning Analytics\Learning-AI\Learning_Analytics-API\venv\Lib\site-packages\google\genai\_api_client.py", line 1105, in _request_once
    errors.APIError.raise_for_response(response)
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^
  File "D:\Learning Analytics\Learning-AI\Learning_Analytics-API\venv\Lib\site-packages\google\genai\errors.py", line 108, in raise_for_response
    raise ClientError(status_code, response_json, response)
google.genai.errors.ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-3-flash\nPlease retry in 36.626274931s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-3-flash', 'location': 'global'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '36s'}]}}
2026-01-22 12:35:23,316 - file_utils - INFO - Cleaned up file: D:\Learning Analytics\Learning-AI\Question_and_Answer_Generation_with_Feeddack\uploads\13-queryexecution.pdf
2026-01-22 12:35:23,317 - routes - ERROR - Question generation failed: Gemini API Error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-3-flash\nPlease retry in 36.626274931s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-3-flash', 'location': 'global'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '36s'}]}}
2026-01-22 12:35:23,321 - werkzeug - INFO - 127.0.0.1 - - [22/Jan/2026 12:35:23] "[32mPOST /generate HTTP/1.1[0m" 302 -
2026-01-22 12:35:23,328 - routes - INFO - Rendering Question generator page
2026-01-22 12:35:23,330 - werkzeug - INFO - 127.0.0.1 - - [22/Jan/2026 12:35:23] "GET /mcq-generator HTTP/1.1" 200 -
2026-01-22 12:38:42,906 - routes - INFO - Rendering home page
2026-01-22 12:38:42,908 - werkzeug - INFO - 127.0.0.1 - - [22/Jan/2026 12:38:42] "GET / HTTP/1.1" 200 -
2026-01-22 12:38:45,117 - routes - INFO - Rendering Question generator page
2026-01-22 12:38:45,118 - werkzeug - INFO - 127.0.0.1 - - [22/Jan/2026 12:38:45] "GET /mcq-generator HTTP/1.1" 200 -
2026-01-22 12:38:54,366 - routes - INFO - Received Question generation request
2026-01-22 12:38:54,375 - validation - INFO - File and parameters validated successfully.
2026-01-22 12:38:54,375 - file_utils - DEBUG - File 13-queryexecution.pdf allowed: True
2026-01-22 12:38:54,382 - file_utils - INFO - File saved to: D:\Learning Analytics\Learning-AI\Question_and_Answer_Generation_with_Feeddack\uploads\13-queryexecution.pdf
2026-01-22 12:38:54,542 - pdf_extraction_util - INFO - Successfully extracted 38407 characters from 13-queryexecution.pdf
2026-01-22 12:38:54,548 - routes - INFO - Successfully saved content for 13-queryexecution.pdf to Context table.
2026-01-22 12:38:55,405 - question_generation - INFO - QuestionGenerator initialized with model: gemini-3-flash-preview
2026-01-22 12:38:55,406 - question_generation - INFO - Generating structured content using model gemini-3-flash-preview...
2026-01-22 12:38:55,406 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2026-01-22 12:38:55,408 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2026-01-22 12:38:55,425 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001E5461016E0>
2026-01-22 12:38:55,425 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001E5460F0550> server_hostname='generativelanguage.googleapis.com' timeout=None
2026-01-22 12:38:55,449 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001E54623F1D0>
2026-01-22 12:38:55,449 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2026-01-22 12:38:55,450 - httpcore.http11 - DEBUG - send_request_headers.complete
2026-01-22 12:38:55,450 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2026-01-22 12:38:55,450 - httpcore.http11 - DEBUG - send_request_body.complete
2026-01-22 12:38:55,451 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2026-01-22 12:38:55,881 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Type', b'application/json; charset=UTF-8'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 22 Jan 2026 07:08:55 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=414'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2026-01-22 12:38:55,882 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-3-flash-preview:generateContent "HTTP/1.1 429 Too Many Requests"
2026-01-22 12:38:55,882 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2026-01-22 12:38:55,883 - httpcore.http11 - DEBUG - receive_response_body.complete
2026-01-22 12:38:55,883 - httpcore.http11 - DEBUG - response_closed.started
2026-01-22 12:38:55,883 - httpcore.http11 - DEBUG - response_closed.complete
2026-01-22 12:38:55,884 - question_generation - ERROR - Gemini API Error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-3-flash\nPlease retry in 4.042346254s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-3-flash', 'location': 'global'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '4s'}]}}
Traceback (most recent call last):
  File "D:\Learning Analytics\Learning-AI\Question_and_Answer_Generation_with_Feeddack\app\services\question_generation.py", line 270, in _generate_structured_content
    response = self.client.models.generate_content(
        model=self.model_name,
        contents=[prompt],
        config=generation_config
    )
  File "D:\Learning Analytics\Learning-AI\Learning_Analytics-API\venv\Lib\site-packages\google\genai\models.py", line 4983, in generate_content
    response = self._generate_content(
        model=model, contents=contents, config=parsed_config
    )
  File "D:\Learning Analytics\Learning-AI\Learning_Analytics-API\venv\Lib\site-packages\google\genai\models.py", line 3795, in _generate_content
    response = self._api_client.request(
        'post', path, request_dict, http_options
    )
  File "D:\Learning Analytics\Learning-AI\Learning_Analytics-API\venv\Lib\site-packages\google\genai\_api_client.py", line 1292, in request
    response = self._request(http_request, http_options, stream=False)
  File "D:\Learning Analytics\Learning-AI\Learning_Analytics-API\venv\Lib\site-packages\google\genai\_api_client.py", line 1128, in _request
    return self._retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
           ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Learning Analytics\Learning-AI\Learning_Analytics-API\venv\Lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
  File "D:\Learning Analytics\Learning-AI\Learning_Analytics-API\venv\Lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
  File "D:\Learning Analytics\Learning-AI\Learning_Analytics-API\venv\Lib\site-packages\tenacity\__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
          ~~~~~~~~~~~~~~~~~^^
  File "D:\Learning Analytics\Learning-AI\Learning_Analytics-API\venv\Lib\site-packages\tenacity\__init__.py", line 187, in reraise
    raise self.last_attempt.result()
          ~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python313\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ~~~~~~~~~~~~~~~~~^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python313\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "D:\Learning Analytics\Learning-AI\Learning_Analytics-API\venv\Lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
  File "D:\Learning Analytics\Learning-AI\Learning_Analytics-API\venv\Lib\site-packages\google\genai\_api_client.py", line 1105, in _request_once
    errors.APIError.raise_for_response(response)
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^
  File "D:\Learning Analytics\Learning-AI\Learning_Analytics-API\venv\Lib\site-packages\google\genai\errors.py", line 108, in raise_for_response
    raise ClientError(status_code, response_json, response)
google.genai.errors.ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-3-flash\nPlease retry in 4.042346254s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-3-flash', 'location': 'global'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '4s'}]}}
2026-01-22 12:38:55,890 - file_utils - INFO - Cleaned up file: D:\Learning Analytics\Learning-AI\Question_and_Answer_Generation_with_Feeddack\uploads\13-queryexecution.pdf
2026-01-22 12:38:55,891 - routes - ERROR - Question generation failed: Gemini API Error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-3-flash\nPlease retry in 4.042346254s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-3-flash', 'location': 'global'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '4s'}]}}
2026-01-22 12:38:55,895 - werkzeug - INFO - 127.0.0.1 - - [22/Jan/2026 12:38:55] "[32mPOST /generate HTTP/1.1[0m" 302 -
2026-01-22 12:38:55,903 - routes - INFO - Rendering Question generator page
2026-01-22 12:38:55,904 - werkzeug - INFO - 127.0.0.1 - - [22/Jan/2026 12:38:55] "GET /mcq-generator HTTP/1.1" 200 -
2026-01-22 12:44:23,306 - routes - INFO - Received Question generation request
2026-01-22 12:44:23,333 - validation - INFO - File and parameters validated successfully.
2026-01-22 12:44:23,334 - file_utils - DEBUG - File 13-queryexecution.pdf allowed: True
2026-01-22 12:44:23,344 - file_utils - INFO - File saved to: D:\Learning Analytics\Learning-AI\Question_and_Answer_Generation_with_Feeddack\uploads\13-queryexecution.pdf
2026-01-22 12:44:23,495 - pdf_extraction_util - INFO - Successfully extracted 38407 characters from 13-queryexecution.pdf
2026-01-22 12:44:23,501 - routes - INFO - Successfully saved content for 13-queryexecution.pdf to Context table.
2026-01-22 12:44:24,363 - question_generation - INFO - QuestionGenerator initialized with model: gemini-3-flash-preview
2026-01-22 12:44:24,364 - question_generation - INFO - Generating structured content using model gemini-3-flash-preview...
2026-01-22 12:44:24,364 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2026-01-22 12:44:24,366 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2026-01-22 12:44:24,382 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001E5460E8490>
2026-01-22 12:44:24,382 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001E5460F0D70> server_hostname='generativelanguage.googleapis.com' timeout=None
2026-01-22 12:44:24,400 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001E5460E86B0>
2026-01-22 12:44:24,400 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2026-01-22 12:44:24,400 - httpcore.http11 - DEBUG - send_request_headers.complete
2026-01-22 12:44:24,400 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2026-01-22 12:44:24,401 - httpcore.http11 - DEBUG - send_request_body.complete
2026-01-22 12:44:24,401 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2026-01-22 12:44:24,808 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Type', b'application/json; charset=UTF-8'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 22 Jan 2026 07:14:24 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=395'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2026-01-22 12:44:24,809 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-3-flash-preview:generateContent "HTTP/1.1 429 Too Many Requests"
2026-01-22 12:44:24,809 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2026-01-22 12:44:24,810 - httpcore.http11 - DEBUG - receive_response_body.complete
2026-01-22 12:44:24,811 - httpcore.http11 - DEBUG - response_closed.started
2026-01-22 12:44:24,811 - httpcore.http11 - DEBUG - response_closed.complete
2026-01-22 12:44:24,811 - question_generation - ERROR - Gemini API Error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-3-flash\nPlease retry in 35.113458164s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-3-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '35s'}]}}
Traceback (most recent call last):
  File "D:\Learning Analytics\Learning-AI\Question_and_Answer_Generation_with_Feeddack\app\services\question_generation.py", line 270, in _generate_structured_content
    response = self.client.models.generate_content(
        model=self.model_name,
        contents=[prompt],
        config=generation_config
    )
  File "D:\Learning Analytics\Learning-AI\Learning_Analytics-API\venv\Lib\site-packages\google\genai\models.py", line 4983, in generate_content
    response = self._generate_content(
        model=model, contents=contents, config=parsed_config
    )
  File "D:\Learning Analytics\Learning-AI\Learning_Analytics-API\venv\Lib\site-packages\google\genai\models.py", line 3795, in _generate_content
    response = self._api_client.request(
        'post', path, request_dict, http_options
    )
  File "D:\Learning Analytics\Learning-AI\Learning_Analytics-API\venv\Lib\site-packages\google\genai\_api_client.py", line 1292, in request
    response = self._request(http_request, http_options, stream=False)
  File "D:\Learning Analytics\Learning-AI\Learning_Analytics-API\venv\Lib\site-packages\google\genai\_api_client.py", line 1128, in _request
    return self._retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
           ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Learning Analytics\Learning-AI\Learning_Analytics-API\venv\Lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
  File "D:\Learning Analytics\Learning-AI\Learning_Analytics-API\venv\Lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
  File "D:\Learning Analytics\Learning-AI\Learning_Analytics-API\venv\Lib\site-packages\tenacity\__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
          ~~~~~~~~~~~~~~~~~^^
  File "D:\Learning Analytics\Learning-AI\Learning_Analytics-API\venv\Lib\site-packages\tenacity\__init__.py", line 187, in reraise
    raise self.last_attempt.result()
          ~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python313\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ~~~~~~~~~~~~~~~~~^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python313\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "D:\Learning Analytics\Learning-AI\Learning_Analytics-API\venv\Lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
  File "D:\Learning Analytics\Learning-AI\Learning_Analytics-API\venv\Lib\site-packages\google\genai\_api_client.py", line 1105, in _request_once
    errors.APIError.raise_for_response(response)
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^
  File "D:\Learning Analytics\Learning-AI\Learning_Analytics-API\venv\Lib\site-packages\google\genai\errors.py", line 108, in raise_for_response
    raise ClientError(status_code, response_json, response)
google.genai.errors.ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-3-flash\nPlease retry in 35.113458164s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-3-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '35s'}]}}
2026-01-22 12:44:24,819 - file_utils - INFO - Cleaned up file: D:\Learning Analytics\Learning-AI\Question_and_Answer_Generation_with_Feeddack\uploads\13-queryexecution.pdf
2026-01-22 12:44:24,820 - routes - ERROR - Question generation failed: Gemini API Error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-3-flash\nPlease retry in 35.113458164s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-3-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '35s'}]}}
2026-01-22 12:44:24,824 - werkzeug - INFO - 127.0.0.1 - - [22/Jan/2026 12:44:24] "[32mPOST /generate HTTP/1.1[0m" 302 -
2026-01-22 12:44:24,835 - routes - INFO - Rendering Question generator page
2026-01-22 12:44:24,836 - werkzeug - INFO - 127.0.0.1 - - [22/Jan/2026 12:44:24] "GET /mcq-generator HTTP/1.1" 200 -
2026-01-22 14:05:49,145 - routes - INFO - Received Question generation request
2026-01-22 14:05:49,156 - validation - INFO - File and parameters validated successfully.
2026-01-22 14:05:49,156 - file_utils - DEBUG - File 13-queryexecution.pdf allowed: True
2026-01-22 14:05:49,163 - file_utils - INFO - File saved to: D:\Learning Analytics\Learning-AI\Question_and_Answer_Generation_with_Feeddack\uploads\13-queryexecution.pdf
2026-01-22 14:05:49,290 - pdf_extraction_util - INFO - Successfully extracted 38407 characters from 13-queryexecution.pdf
2026-01-22 14:05:49,298 - httpcore.connection - DEBUG - close.started
2026-01-22 14:05:49,299 - httpcore.connection - DEBUG - close.complete
2026-01-22 14:05:49,299 - httpcore.connection - DEBUG - close.started
2026-01-22 14:05:49,300 - httpcore.connection - DEBUG - close.complete
2026-01-22 14:05:49,300 - httpcore.connection - DEBUG - close.started
2026-01-22 14:05:49,301 - httpcore.connection - DEBUG - close.complete
2026-01-22 14:05:49,324 - routes - INFO - Successfully saved content for 13-queryexecution.pdf to Context table.
2026-01-22 14:05:50,249 - question_generation - INFO - QuestionGenerator initialized with model: gemini-3-flash-preview
2026-01-22 14:05:50,251 - question_generation - INFO - Generating structured content using model gemini-3-flash-preview...
2026-01-22 14:05:50,251 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2026-01-22 14:05:50,254 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2026-01-22 14:05:50,287 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001E54603BD50>
2026-01-22 14:05:50,287 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001E5461C7ED0> server_hostname='generativelanguage.googleapis.com' timeout=None
2026-01-22 14:05:50,310 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001E54603B550>
2026-01-22 14:05:50,311 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2026-01-22 14:05:50,313 - httpcore.http11 - DEBUG - send_request_headers.complete
2026-01-22 14:05:50,313 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2026-01-22 14:05:50,314 - httpcore.http11 - DEBUG - send_request_body.complete
2026-01-22 14:05:50,314 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2026-01-22 14:06:22,835 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 22 Jan 2026 08:36:22 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=32503'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2026-01-22 14:06:22,836 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-3-flash-preview:generateContent "HTTP/1.1 200 OK"
2026-01-22 14:06:22,837 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2026-01-22 14:06:22,839 - httpcore.http11 - DEBUG - receive_response_body.complete
2026-01-22 14:06:22,840 - httpcore.http11 - DEBUG - response_closed.started
2026-01-22 14:06:22,840 - httpcore.http11 - DEBUG - response_closed.complete
2026-01-22 14:06:22,844 - google_genai.types - WARNING - Warning: there are non-text parts in the response: ['thought_signature'], returning concatenated parsed result from text parts. Check the full candidates.content.parts accessor to get the full model response.
2026-01-22 14:06:22,845 - google_genai.types - WARNING - Warning: there are non-text parts in the response: ['thought_signature'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.
2026-01-22 14:06:22,845 - question_generation - INFO - Successfully separated 5 questions and 5 answer key items.
2026-01-22 14:06:22,846 - file_utils - INFO - Cleaned up file: D:\Learning Analytics\Learning-AI\Question_and_Answer_Generation_with_Feeddack\uploads\13-queryexecution.pdf
2026-01-22 14:06:22,847 - pdf_generation - INFO - Creating PDF file: D:\Learning Analytics\Learning-AI\Question_and_Answer_Generation_with_Feeddack\results\generated_mcqs_13-queryexecution_questions.pdf
2026-01-22 14:06:22,859 - fpdf.fpdf - DEBUG - Page break on page 1 at y=275 for element of height 8 > 277
2026-01-22 14:06:22,863 - fpdf.output - DEBUG - Final size summary of the biggest document sections:
2026-01-22 14:06:22,863 - fpdf.output - DEBUG - - pages: 2.4KiB
2026-01-22 14:06:22,863 - fpdf.output - DEBUG - - fonts: 304.0B
2026-01-22 14:06:22,863 - pdf_generation - INFO - PDF successfully generated at D:\Learning Analytics\Learning-AI\Question_and_Answer_Generation_with_Feeddack\results\generated_mcqs_13-queryexecution_questions.pdf
2026-01-22 14:06:22,863 - file_utils - INFO - Saving TXT results for: 13-queryexecution.pdf
2026-01-22 14:06:22,864 - pdf_generation - INFO - Saving merged questions to text file: generated_mcqs_13-queryexecution_key.txt
2026-01-22 14:06:22,866 - pdf_generation - INFO - Successfully saved 5 questions to text file.
2026-01-22 14:06:22,866 - file_utils - INFO - TXT file saved: generated_mcqs_13-queryexecution_key.txt
2026-01-22 14:06:22,866 - routes - INFO - Successfully generated 5 questions.
2026-01-22 14:06:22,876 - httpcore.connection - DEBUG - close.started
2026-01-22 14:06:22,876 - httpcore.connection - DEBUG - close.complete
2026-01-22 14:06:22,879 - werkzeug - INFO - 127.0.0.1 - - [22/Jan/2026 14:06:22] "POST /generate HTTP/1.1" 200 -
2026-01-22 14:06:36,069 - question_generation - INFO - QuestionGenerator initialized with model: gemini-3-flash-preview
2026-01-22 14:06:36,069 - question_generation - INFO - Generating structured content using model gemini-3-flash-preview...
2026-01-22 14:06:36,069 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2026-01-22 14:06:36,070 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2026-01-22 14:06:36,088 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001E5461E1D60>
2026-01-22 14:06:36,088 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001E5460F0EB0> server_hostname='generativelanguage.googleapis.com' timeout=None
2026-01-22 14:06:36,109 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001E5461E19A0>
2026-01-22 14:06:36,109 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2026-01-22 14:06:36,110 - httpcore.http11 - DEBUG - send_request_headers.complete
2026-01-22 14:06:36,110 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2026-01-22 14:06:36,110 - httpcore.http11 - DEBUG - send_request_body.complete
2026-01-22 14:06:36,110 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2026-01-22 14:06:49,756 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 22 Jan 2026 08:36:49 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=13629'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2026-01-22 14:06:49,757 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-3-flash-preview:generateContent "HTTP/1.1 200 OK"
2026-01-22 14:06:49,758 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2026-01-22 14:06:49,759 - httpcore.http11 - DEBUG - receive_response_body.complete
2026-01-22 14:06:49,759 - httpcore.http11 - DEBUG - response_closed.started
2026-01-22 14:06:49,759 - httpcore.http11 - DEBUG - response_closed.complete
2026-01-22 14:06:49,760 - google_genai.types - WARNING - Warning: there are non-text parts in the response: ['thought_signature'], returning concatenated parsed result from text parts. Check the full candidates.content.parts accessor to get the full model response.
2026-01-22 14:06:49,761 - google_genai.types - WARNING - Warning: there are non-text parts in the response: ['thought_signature'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.
2026-01-22 14:06:49,762 - pdf_generation - INFO - Creating PDF file: D:\Learning Analytics\Learning-AI\Question_and_Answer_Generation_with_Feeddack\results\generated_mcqs_13-queryexecution_questions.pdf
2026-01-22 14:06:49,772 - fpdf.fpdf - DEBUG - Page break on page 1 at y=277 for element of height 6 > 277
2026-01-22 14:06:49,775 - fpdf.output - DEBUG - Final size summary of the biggest document sections:
2026-01-22 14:06:49,775 - fpdf.output - DEBUG - - pages: 1.9KiB
2026-01-22 14:06:49,775 - fpdf.output - DEBUG - - fonts: 304.0B
2026-01-22 14:06:49,776 - pdf_generation - INFO - PDF successfully generated at D:\Learning Analytics\Learning-AI\Question_and_Answer_Generation_with_Feeddack\results\generated_mcqs_13-queryexecution_questions.pdf
2026-01-22 14:06:49,776 - file_utils - INFO - Saving TXT results for: 13-queryexecution.pdf
2026-01-22 14:06:49,776 - pdf_generation - INFO - Saving merged questions to text file: generated_mcqs_13-queryexecution_key.txt
2026-01-22 14:06:49,777 - pdf_generation - INFO - Successfully saved 4 questions to text file.
2026-01-22 14:06:49,777 - file_utils - INFO - TXT file saved: generated_mcqs_13-queryexecution_key.txt
2026-01-22 14:06:49,777 - httpcore.connection - DEBUG - close.started
2026-01-22 14:06:49,777 - httpcore.connection - DEBUG - close.complete
2026-01-22 14:06:49,779 - werkzeug - INFO - 127.0.0.1 - - [22/Jan/2026 14:06:49] "POST /reframe_question HTTP/1.1" 200 -
2026-01-22 14:06:49,786 - routes - INFO - Display Results Called
2026-01-22 14:06:49,787 - werkzeug - INFO - 127.0.0.1 - - [22/Jan/2026 14:06:49] "GET /display_results HTTP/1.1" 200 -
2026-01-22 14:09:14,192 - werkzeug - INFO -  * Detected change in 'D:\\Learning Analytics\\Learning-AI\\Question_and_Answer_Generation_with_Feeddack\\app\\routes.py', reloading
2026-01-22 14:09:14,195 - ragas._analytics - DEBUG - AnalyticsBatcher shutdown complete
